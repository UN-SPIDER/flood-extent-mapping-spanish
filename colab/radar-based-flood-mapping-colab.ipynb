{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "radar-based-flood-mapping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "721px",
        "left": "82px",
        "top": "111.133px",
        "width": "237px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHPuuAfTW3_I"
      },
      "source": [
        "# <img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/header.png?raw=1\" width=\"1000\"/>\n",
        "\n",
        "\n",
        "# Mapeo de inundaciones mediante imágenes de radar Sentinel-1\n",
        "\n",
        "<img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/example.png?raw=1\" width=\"1000\"/>\n",
        "\n",
        "***\n",
        "\n",
        "El objetivo de esta práctica recomendada The objective of this [práctica recomendada](https://un-spider.org/advisory-support/recommended-practices) es determinar la extensión de las áreas inundadas. Mediante el uso de imágenes satelitales de radar de apertura sintética (SAR) para el mapeo de la extensión de las inundaciones. Esta práctica, constituye una solución viable para el procesamiento rápido de imágenes Sentinel-1, ya que proporciona información de inundaciones casi en tiempo real a las agencias de ayuda para apoyar la acción humanitaria. La alta confiabilidad de los datos, así como la ausencia de restricciones geográficas y la accesibilidad a las zonas afectadas, enfatizan el potencial de esta tecnología.\n",
        "\n",
        "Este cuaderno de Jupyter está optimizado para su uso con Google Colab. Al ser un entorno basado en la computación en la nube, aprovecha los recursos técnicos externos y, por lo tanto, permite que esta herramienta pueda funcionar en dispositivos con potencia informática limitada, como teléfonos y tabletas, en áreas con escaso ancho de banda. \n",
        "Este cuaderno de Jupyter Notebook cubre toda la cadena de procesamiento, desde la consulta de datos, descarga, hasta la exportación de un producto final de máscara de inundación mediante el uso de imágenes SAR de libre acceso de Sentinel-1. El flujo de trabajo de la herramienta sigue la práctica recomendada de ONU-SPIDER sobre [mapeo de inundaciones basado en radar](https://un-spider.org/advisory-support/recommended-practices/recommended-practice-radar-based-flood-mapping), como se ilustra en la siguiente figura. Después de ingresar las especificaciones del usuario, los datos de Sentinel-1 se pueden descargar directamente desde del <a href=\"https://scihub.copernicus.eu/\"> Copernicus Open Access Hub </a>. Posteriormente, los datos se procesan y almacenan en una variedad de formatos de salida.\n",
        "\n",
        "<img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/charts/chart0.png?raw=1\" width=\"1000\"/>\n",
        "\n",
        "***\n",
        "\n",
        "***Estructura del archivo***  \n",
        "El Jupyter Notebook crea una carpeta llamada *'mapeo-de-extensión-de-inundación'* en Google Drive. Las imágenes de Sentinel-1 deben almacenarse en una subcarpeta llamada *'entrada'*. Si no se proporciona ninguna imagen, la subcarpeta se creará automáticamente al acceder a la herramienta y descargar los datos del <a href=\"https://scihub.copernicus.eu/\"> Copernicus Open Access Hub </a>. Si posee un área de interés (AOI) (formatos compatibles: GeoJSON, SHP, KML, KMZ), debe colocarse en una subcarpeta llamada *'AOI'*. Si no hay ninguno archivo disponible, una herramienta le permitirá dibujar manualmente y/o cargar archivos de AOI almacenados localmente. Por razones de selección automática de archivos, se recomienda colocar solo un solo archivo AOI en la carpeta correspondiente. Sin embargo, si existen varios archivos, los archivos GeoJSON tienen prioridad, seguidos de SHP, KML y KMZ. Los datos procesados se almacenan en una subcarpeta llamada *'salida'*.  \n",
        "Para ejecutar la herramienta sin interacción del usuario, todas las entradas deben estar claramente definidas. Esto significa que la subcarpeta *'entrada'* debe incluir una sola imagen Sentinel-1 y la subcarpeta *'AOI'* un solo archivo AOI. Todos los demás escenarios requieren interacción manual, como descargar datos o definir una AOI.\n",
        "\n",
        "***Limitaticiones***  \n",
        "Existen limitaciones para detectar vegetación inundada e inundaciones en áreas urbanas debido a la retrodispersión de doble rebote. Si las zonas inundadas y no inundadas se distribuyen de manera muy desigual en la imagen, es posible que el histograma no tenga un mínimo local claramente definido, lo que da lugar a resultados incorrectos en el proceso de binarización automática.\n",
        "\n",
        "***\n",
        "\n",
        "## Inicialización\n",
        "\n",
        "El Jupyter Notebook aprovecha la API <a href=\"https://step.esa.int/docs/v6.0/apidoc/engine/\"> ESA SNAP</a> mediante la interfaz de SNAP-Python <i > ágil </i>. El procedimiento de instalación y configuración se incluye en el paso de inicialización de esta herramienta, esto puede tardar unos minutos durante la ejecución inicial de este Jupyter Notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPAS92U46K3X"
      },
      "source": [
        "#@title <font color=#1B7192> Click para iniciar </font>  { display-mode: \"form\" }\r\n",
        "\r\n",
        "#####################################################\r\n",
        "################### CONFIGURACIÓN ###################\r\n",
        "#####################################################\r\n",
        "\r\n",
        "# subir a Google Drive\r\n",
        "import os                                     # acceso a datos\r\n",
        "import google.colab                           # Google Colab\r\n",
        "import time                                   # # tiempo de la evaluación\r\n",
        "import sys\r\n",
        "if not os.path.isdir('/content/drive'):\r\n",
        "    google.colab.drive.mount('/content/drive')\r\n",
        "\r\n",
        "try:\r\n",
        "    import snappy                             # SNAP Python interface\r\n",
        "    import jpy                                # Python-Java bridge\r\n",
        "except:\r\n",
        "    with google.colab.output.use_tags('snappy'):\r\n",
        "        sys.stdout.write('\\nPreparación del entorno conda...\\n')\r\n",
        "        sys.stdout.flush()\r\n",
        "        !pip install -q condacolab &> /dev/null\r\n",
        "        import condacolab\r\n",
        "        condacolab.install_miniconda()\r\n",
        "        sys.stdout.write('\\nInstalación rápida de la interfaz SNAP-Python. Esto puede tardar unos minutos.\\n')\r\n",
        "        sys.stdout.flush()\r\n",
        "        !conda install -c terradue -c conda-forge snap=8.0.0 &> /dev/null\r\n",
        "    google.colab.output.clear(output_tags='snappy')\r\n",
        "try:\r\n",
        "    import geopandas                          # manipulación y análisis de datos\r\n",
        "except:\r\n",
        "    with google.colab.output.use_tags('geopandas'):\r\n",
        "        sys.stdout.write('\\nInstalación del paquete geopandas....\\n')\r\n",
        "        sys.stdout.flush()\r\n",
        "        !pip install geopandas &> /dev/null\r\n",
        "    google.colab.output.clear(output_tags='geopandas')\r\n",
        "try:\r\n",
        "    from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt  # interface to Open Access Hub\r\n",
        "except:\r\n",
        "    with google.colab.output.use_tags('sentinelsat'):\r\n",
        "        sys.stdout.write('\\nInstalación del paquete sentinelsat....\\n')\r\n",
        "        sys.stdout.flush()\r\n",
        "        !pip install sentinelsat &> /dev/null\r\n",
        "    google.colab.output.clear(output_tags='sentinelsat')\r\n",
        "try:\r\n",
        "    from ipyfilechooser import FileChooser    # widget selector de archivos\r\n",
        "except:\r\n",
        "    with google.colab.output.use_tags('ipyfilechooser'):\r\n",
        "        sys.stdout.write('\\nInstalación del paquete ipyfilechooser....\\n')\r\n",
        "        sys.stdout.flush()\r\n",
        "        !pip install ipyfilechooser &> /dev/null\r\n",
        "    google.colab.output.clear(output_tags='ipyfilechooser')\r\n",
        "\r\n",
        "# actualización de estado\r\n",
        "with google.colab.output.use_tags('initialization'):\r\n",
        "    sys.stdout.write('\\n¡Inicialización exitosa!')\r\n",
        "    sys.stdout.flush()\r\n",
        "time.sleep(1)\r\n",
        "google.colab.output.clear(output_tags='initialization')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiOSB4nP540H"
      },
      "source": [
        "## Entradas de usuario\r\n",
        "\r\n",
        "<img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/charts/chart1.png?raw=1\" width=\"1000\"/>\r\n",
        "\r\n",
        "Especifique en la celda del código a continuación: **i)** El tipo polarización que se procesará, **ii)** si los datos se descargarán del <a href=\"https://scihub.copernicus.eu/\"> Copernicus Open Access Hub </a>, y **iii)** si los resultados intermedios deben graficarse durante el proceso. Esta sección también carga los módulos de Python relevantes para el siguiente análisis e inicializa las funcionalidades básicas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0,
          36,
          72,
          84,
          124
        ],
        "id": "oX0CNEX7W3_P",
        "init_cell": true
      },
      "source": [
        "#@title <font color=#1B7192> Click para iniciar </font>  { display-mode: \"form\" }\n",
        "\n",
        "####################################################\n",
        "############### ENTRADAS DE USUARIO ################\n",
        "####################################################\n",
        "\n",
        "# tipo de polarizaciones a procesar\n",
        "Polarisation  = 'VH'                    #@param [\"VH\", \"VV\", \"ambas\"]\n",
        "\n",
        "DownloadImage = True                   #@param {type:\"boolean\"}\n",
        "\n",
        "# mostrar resultados intermedios si se establece en 'true'\n",
        "PlotResults   = True                    #@param {type:\"boolean\"}\n",
        "\n",
        "#####################################################\n",
        "###################### IMPORTAR #####################\n",
        "#####################################################\n",
        "\n",
        "# MODULO                                      # DESCRIPCIÓN\n",
        "import sys\n",
        "try:\n",
        "    import snappy                             # SNAP Python interface\n",
        "    import jpy                                # Python-Java bridge\n",
        "    import geopandas                          # manipulación y análisis de datos\n",
        "    from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt  # interface to Open Access Hub\n",
        "    from ipyfilechooser import FileChooser    # widget selector de archivos\n",
        "except:\n",
        "    sys.exit('\\nPor favor, ejecute primero la celda de inicialización anterior.')\n",
        "import matplotlib.pyplot as plt               # crear visualizaciones\n",
        "import numpy as np                            # computación cientifíca\n",
        "import json                                   # codificador y decodificador GeoJSON\n",
        "import glob                                   # acceso a datos\n",
        "import os                                     # acceso a datos\n",
        "import ipywidgets                             # controles de la UI\n",
        "import time                                   # tiempo de la evaluación\n",
        "import shutil                                 # operaciones de archivo\n",
        "import google.colab                           # Google Colab\n",
        "import folium                                 # visualización\n",
        "from folium import plugins                    # visualización\n",
        "from folium.plugins import MiniMap, Draw, Search # visualización\n",
        "import skimage.filters                        # cálculo del umbral\n",
        "import functools                              # funciones y operaciones de orden superior\n",
        "from datetime import date                     # fecha, hora e intervalos\n",
        "from IPython.display import display           # visualización\n",
        "from osgeo import ogr, gdal, osr              # conversión de datos\n",
        "from zipfile import ZipFile                   # gestión de archivos\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####################################################\n",
        "############# DEFINICIÓN DE FUNSIONES ##############\n",
        "####################################################\n",
        "\n",
        "def getAOI(path):\n",
        "    try:\n",
        "        file = readJSONFromAOI(path)\n",
        "    except:\n",
        "        print('No se encontró ningún archivo AOI. Dibuje y descargue el área de interés haciendo clic en el botón -Export- dentro del')\n",
        "        print('mapa o cargue directamente un archivo AOI almacenado localmente usando el cuadro de diálogo debajo del mapa.\\n')\n",
        "        # crea el mapa\n",
        "        f = folium.Figure(height=500)\n",
        "        m = folium.Map(location=[0, 0], zoom_start=2.5, control_scale=True).add_to(f)\n",
        "        # agregar el mapa base personalizado\n",
        "        basemaps['Google Satellite Hybrid'].add_to(m)\n",
        "        # agregar un panel de control de capa al mapa\n",
        "        m.add_child(folium.LayerControl())\n",
        "        # agregar minimapa\n",
        "        m.add_child(MiniMap(tile_layer=basemaps['Google Satellite'], position='bottomright'))\n",
        "        # agregar control de dibujo\n",
        "        draw = Draw(export=True, filename='AOI_manual_%s.geojson' % str(date.today()), draw_options={'polyline': False, 'circle': False, 'marker': False, 'circlemarker': False})\n",
        "        draw.add_to(m)\n",
        "        # mostrar el mapa\n",
        "        updater = display(f, display_id='m')\n",
        "        print('\\n')\n",
        "        # cargar la sección \n",
        "        os.chdir('/content')\n",
        "        uploaded = google.colab.files.upload()\n",
        "        for fn in uploaded.keys():\n",
        "            # copiar el archivo cargado a la carpeta GDrive\n",
        "            aoi_path = os.path.join(directory, 'AOI')\n",
        "            if not os.path.isdir(aoi_path):\n",
        "                os.mkdir(aoi_path)\n",
        "            shutil.copy2('/content/%s' % fn, aoi_path)\n",
        "            # elimina el archivo original\n",
        "            os.remove('/content/%s' % fn)\n",
        "            file_path = '%s/%s' % (aoi_path, fn)\n",
        "        file = readJSONFromAOI(aoi_path)\n",
        "    \n",
        "    return file\n",
        "\n",
        "\n",
        "\n",
        "# La función busca el archivo del AOI, si no esta en formato GeoJSON se convierte y devuelve la ruta\n",
        "def readJSONFromAOI(path):\n",
        "    # busca el archivo GeoJSON en la subcarpeta 'AOI'\n",
        "    if len(glob.glob('%s/*.geojson' % path)) == 1:\n",
        "        file = glob.glob('%s/*.geojson' % path)[0]\n",
        "    elif len(glob.glob('%s/*.json' % path)) == 1:\n",
        "        file = glob.glob('%s/*.json' % path)[0]\n",
        "\n",
        "    # convierte el SHP a GeoJSON si no es proporcionado el JSON\n",
        "    elif len(glob.glob('%s/*.shp' % path)) == 1:\n",
        "        file_name = os.path.splitext(glob.glob('%s/*.shp' % path)[0])[0].split('/')[-1]\n",
        "        shp_file = geopandas.read_file(glob.glob('%s/*.shp' % path)[0])\n",
        "        shp_file.to_file('%s/%s.json' % (path, file_name), driver='GeoJSON')\n",
        "        file = glob.glob('%s/*.json' % path)[0]\n",
        "\n",
        "    # convierte el KML a GeoJSON si no es proporcionado el JSON \n",
        "    elif len(glob.glob('%s/*.kml' % path)) == 1:\n",
        "        file_name = os.path.splitext(glob.glob('%s/*.kml' % path)[0])[0].split('/')[-1]\n",
        "        kml_file = gdal.OpenEx(glob.glob('%s/*.kml' % path)[0])\n",
        "        ds = gdal.VectorTranslate('%s/%s.json' % (path, file_name), kml_file, format='GeoJSON')\n",
        "        del ds\n",
        "        file = glob.glob('%s/*.json' % path)[0]\n",
        "\n",
        "    # convierte el KMZ a JSON si no se proporciona un JSON, SHP o KML\n",
        "    elif len(glob.glob('%s/*.kmz' % path)) == 1:\n",
        "        # open KMZ file and extract data\n",
        "        with ZipFile(glob.glob('%s/*.kmz' % path)[0], 'r') as kmz:\n",
        "            folder = os.path.splitext(glob.glob('%s/*.kmz' % path)[0])[0]\n",
        "            kmz.extractall(folder)\n",
        "        # convierte el KML a GeoJSON si la carpeta extraída contiene un archivo KML\n",
        "        if len(glob.glob('%s/*.kml' % folder)) == 1:\n",
        "            kml_file = gdal.OpenEx(glob.glob('%s/*.kml' % folder)[0])\n",
        "            ds = gdal.VectorTranslate('%s/%s.json' % (path, folder.split('/')[-1]), kml_file, format='GeoJSON')\n",
        "            del ds\n",
        "            file = glob.glob('%s/*.json' % path)[0]\n",
        "            # elimina el archivo comprimido KMZ\n",
        "            shutil.rmtree(folder)\n",
        "    # Permite cargar archivos AOI o dibujar una AOI manualmente si no se encontra ningún archivo\n",
        "    else:\n",
        "        raise FileNotFoundError\n",
        "\n",
        "    return file\n",
        "\n",
        "\n",
        "# gráfica el histograma de la banda de entrada y el umbral\n",
        "# SNAP API: https://step.esa.int/docs/v6.0/apidoc/engine/\n",
        "def plotBand(band, threshold, binary=False):\n",
        "    # realce de color\n",
        "    vmin, vmax = 0, 1\n",
        "    # lee los valores de los píxeles\n",
        "    w = band.getRasterWidth()\n",
        "    h = band.getRasterHeight()\n",
        "    band_data = np.zeros(w * h, np.float32)\n",
        "    band.readPixels(0, 0, w, h, band_data)\n",
        "    band_data.shape = h, w\n",
        "    # realce de color\n",
        "    if binary:\n",
        "        cmap = plt.get_cmap('binary')\n",
        "    else:\n",
        "        vmin = np.percentile(band_data, 2.5)\n",
        "        vmax = np.percentile(band_data, 97.5)\n",
        "        cmap = plt.get_cmap('gray')\n",
        "    # gráfica la banda\n",
        "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16,6))\n",
        "    ax1.imshow(band_data, cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "    ax1.set_title(band.getName())\n",
        "    # gráfica el histograma\n",
        "    band_data.shape = h * w \n",
        "    ax2.hist(np.asarray(band_data[band_data != 0], dtype='float'), bins=2048)\n",
        "    ax2.axvline(x=threshold, color='r')\n",
        "    ax2.set_title('Histogram: %s' % band.getName())\n",
        "    \n",
        "    for ax in fig.get_axes():\n",
        "        ax.label_outer()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####################################################\n",
        "###################### CÓDIGO ######################\n",
        "####################################################   \n",
        "        \n",
        "# selecciona el directorio de trabajo\n",
        "directory = '/content/drive/MyDrive/mapeo-de-extensión-de-inundación'\n",
        "if not os.path.isdir(directory):\n",
        "    os.mkdir(directory)\n",
        "\n",
        "# Agrega un mapa base personalizado a folium\n",
        "basemaps = {\n",
        "    'Google Satellite Hybrid': folium.TileLayer(\n",
        "        tiles = 'https://mt1.google.com/vt/lyrs=y&x={x}&y={y}&z={z}',\n",
        "        attr = 'Google',\n",
        "        name = 'Google Satellite',\n",
        "        overlay = True,\n",
        "        control = True,\n",
        "        show = False\n",
        "    ),\n",
        "    'Google Satellite': folium.TileLayer(\n",
        "        tiles = 'https://mt1.google.com/vt/lyrs=s&x={x}&y={y}&z={z}',\n",
        "        attr = 'Google',\n",
        "        name = 'Google Satellite',\n",
        "        overlay = True,\n",
        "        control = True,\n",
        "        show = False\n",
        "    )\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aSEaXF1W3_S"
      },
      "source": [
        "## Descargar imagen\n",
        "\n",
        "<img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/charts/chart2.png?raw=1\" width=\"1000\"/>\n",
        "\n",
        "Esta sección permite el acceso y la descarga de datos interactivos desde el <a href=\"https://scihub.copernicus.eu/\"> Copernicus Open Access Hub </a>. Requiere los respectivos datos de inicio de sesión y el período de detección deseado. Si se proporciona un archivo de área de interés AOI en la subcarpeta *'AOI'*, la herramienta busca y muestra las imágenes Sentinel-1 disponibles. Si no se proporciona un archivo AOI, un mapa interactivo permite dibujar y descargar el área de interés haciendo clic en el botón *'Exportar'* - dentro del mapa o cargar directamente un archivo AOI almacenado localmente. Al pasar el cursor sobre una imagen de Sentinel-1, se muestran el índice de mosaico y las fechas de ingestión. La siguiente tabla resume la información sobre todos los mosaicos disponibles y permite la descarga. Los datos se almacenan en la subcarpeta *'entrada'* creada automáticamente. El Open Access Hub proporciona un archivo en línea de al menos el último año de productos para su descarga inmediata. El acceso a productos anteriores que ya no están disponibles en línea activará automáticamente la recuperación de los archivos a largo plazo. La descarga real puede ser iniciada por el usuario una vez que se restauran los datos (dentro de las 24 horas)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0,
          7,
          30,
          39,
          57
        ],
        "id": "wvsKF_MmW3_U"
      },
      "source": [
        "#@title <font color=#1B7192> Click para iniciar </font>  { display-mode: \"form\" }\n",
        "\n",
        "####################################################\n",
        "############### ENTRADAS DE USUARIO ################\n",
        "####################################################\n",
        "\n",
        "Username      = ''              #@param {type:\"string\"}\n",
        "Password      = ''              #@param {type:\"string\"}\n",
        "SensingPeriod_Start  = '2021-01-01'     #@param {type:\"date\"}\n",
        "SensingPeriod_Stop   = '2021-01-08'     #@param {type:\"date\"}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####################################################\n",
        "############# DEFINICIÓN DE FUNSIONES ##############\n",
        "####################################################\n",
        "\n",
        "# buscar y mostrar mosaicos Sentinel-1 disponibles\n",
        "def queri(footprint):\n",
        "    # print status\n",
        "    with google.colab.output.use_tags('loading'):\n",
        "        sys.stdout.write('\\nCargando...')\n",
        "        sys.stdout.flush()\n",
        "    # buscar productos Copernicus del Open Access Hub con respecto a la zona de entrada y el período de detección\n",
        "    period = (date(int(SensingPeriod_Start.split('-')[0]), int(SensingPeriod_Start.split('-')[1]), int(SensingPeriod_Start.split('-')[2])),\n",
        "              date(int(SensingPeriod_Stop.split('-')[0]), int(SensingPeriod_Stop.split('-')[1]), int(SensingPeriod_Stop.split('-')[2])))\n",
        "    try:\n",
        "        products = api.query(footprint, date=period, platformname='Sentinel-1', producttype='GRD')\n",
        "        print('Conectado con éxito al Copernicus Open Access Hub.\\n', flush=True)\n",
        "    except:\n",
        "        sys.exit('\\nLos datos de inicio de sesión no son válidos. Cambie el nombre de usuario y/o la contraseña.')\n",
        "    # convertir el GeoJSON para graficar\n",
        "    products_json = api.to_geojson(products)\n",
        "    # generar una advertencia de que no hay imagen disponible en un período de detección dado\n",
        "    if not products_json['features']:\n",
        "        sys.exit('\\nNo hay imágenes Sentinel-1 disponibles. Cambie el período de detección en la sección de entrada del usuario.')\n",
        "    # convierte a dataframe para la visualización de tablas\n",
        "    products_df = api.to_dataframe(products)\n",
        "    # agrega un índice al dataframe\n",
        "    indices = []\n",
        "    for i in range (1, len(products_df.index)+1):\n",
        "        indices.append('Tile %d' % i)\n",
        "        products_json.features[i-1].properties['index'] = ' Tile %d' % i\n",
        "    products_df.insert(0, 'index', indices, True) \n",
        "\n",
        "    # carga los productos para la visualización\n",
        "    s1_tiles = folium.GeoJson(\n",
        "        products_json,\n",
        "        name='S1 tiles',\n",
        "        show=True,\n",
        "        style_function=lambda feature: {'fillColor': 'royalblue', 'fillOpacity' : 0.2},\n",
        "        highlight_function=lambda x: {'fillOpacity' : 0.4},\n",
        "        tooltip=folium.features.GeoJsonTooltip(\n",
        "            fields=['index', 'beginposition'],\n",
        "            aliases=['Índice:','Fecha:'],\n",
        "        ),\n",
        "    ).add_to(m)\n",
        "    # agrega un mapa base personalizado\n",
        "    basemaps['Google Satellite Hybrid'].add_to(m)\n",
        "    # agrega un panel de control a la capa del mapa\n",
        "    m.add_child(folium.LayerControl())\n",
        "    # actualización del estado\n",
        "    google.colab.output.clear(output_tags='loading')\n",
        "    # update map\n",
        "    updater.update(m)\n",
        "\n",
        "    # imprime la tabla con botones de descarga\n",
        "    grid = ipywidgets.GridspecLayout(len(products_df.index)+1, 5, height='250px')\n",
        "    grid[0,0] = ipywidgets.HTML('<h3>Índice</h3>')\n",
        "    grid[0,1] = ipywidgets.HTML('<h3>Fecha</h3>')\n",
        "    grid[0,2] = ipywidgets.HTML('<h3>Polarización</h3>')\n",
        "    grid[0,3] = ipywidgets.HTML('<h3>Tamaño</h3>')\n",
        "    for i in range(len(products_df.index)):\n",
        "        grid[i+1,0] = ipywidgets.Label(products_df['index'][i])\n",
        "        grid[i+1,1] = ipywidgets.Label(str(products_df['beginposition'][i]))\n",
        "        grid[i+1,2] = ipywidgets.Label(products_df['polarisationmode'][i])\n",
        "        grid[i+1,3] = ipywidgets.Label(products_df['size'][i])\n",
        "        grid[i+1,4] = ipywidgets.Button(description = 'Descargar')\n",
        "        grid[i+1,4].on_click(functools.partial(on_downloadButton_clicked, tile_id=products_df.values[i][-1]))\n",
        "    display(grid)\n",
        "\n",
        "# descarga el mosaico elegido de Sentinel-1 en la subcarpeta 'entrada'\n",
        "def on_downloadButton_clicked(b, tile_id):\n",
        "    # obtener información del producto\n",
        "    product_info = api.get_product_odata(tile_id)\n",
        "    # comprobar si el producto está disponible\n",
        "    if product_info['Online']:\n",
        "        # compruebe si existe la carpeta de entrada, si no, cree la carpeta de entrada\n",
        "        input_path = os.path.join(directory, 'entrada')\n",
        "        if not os.path.isdir(input_path):\n",
        "            os.mkdir(input_path)\n",
        "        # cambiar a la subcarpeta 'entrada' para almacenar el producto\n",
        "        os.chdir(input_path)\n",
        "        # actualizar el estado\n",
        "        print('\\nEl producto  %s está en línea. Comenzar descarga.' % tile_id, flush=True)\n",
        "        # descargue el producto\n",
        "        api.download(tile_id)\n",
        "        # volver al directorio de trabajo anterior\n",
        "        os.chdir(directory)\n",
        "    # mensaje de error cuando el producto no está disponible\n",
        "    else:\n",
        "        print('\\nEl producto %s no está en línea. Debe solicitarse manualmente.\\n' % tile_id, flush=True)\n",
        "\n",
        "\n",
        "\n",
        "####################################################\n",
        "###################### CÓDIGO ######################\n",
        "####################################################\n",
        "\n",
        "# comprobar la entrada del usuario si se solicita la descarga de la imagen\n",
        "if DownloadImage:\n",
        "    # cenectar a la API\n",
        "    api = SentinelAPI(Username, Password, 'https://scihub.copernicus.eu/dhus')\n",
        "    # obetener la ruta a la AOI\n",
        "    file = getAOI('%s/AOI' % directory)\n",
        "    # abrir el archivo del AOI GeoJSON y almacenar los datos\n",
        "    with open(file, 'r') as f:\n",
        "        data_json = json.load(f)\n",
        "    # definir el centro del mapa según la estructura interna de GeoJSON\n",
        "    try:\n",
        "        # Formato GeoJSON si se proporciona KMZ\n",
        "        center = [data_json['features'][0]['geometry']['coordinates'][0][0][0][1],\n",
        "                  data_json['features'][0]['geometry']['coordinates'][0][0][0][0]]\n",
        "    except:\n",
        "        # Formato GeoJSON si se proporciona JSON o SHP\n",
        "        center = [data_json['features'][0]['geometry']['coordinates'][0][0][1],\n",
        "                  data_json['features'][0]['geometry']['coordinates'][0][0][0]]\n",
        "    # crea mapa\n",
        "    f = folium.Figure(height=500)\n",
        "    m = folium.Map(location=center, zoom_start=6, control_scale=True).add_to(f)\n",
        "    # agregar el AOI al mapa\n",
        "    folium.GeoJson(file, name='AOI', style_function = lambda x: {'color':'green'}).add_to(m)\n",
        "    footprint = geojson_to_wkt(data_json)\n",
        "    updater = display(f, display_id='m')\n",
        "\n",
        "    # buscar escenas Sentinel-1 disponibles\n",
        "    queri(footprint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoLWzaiXW3_V"
      },
      "source": [
        "## Procesamiento\n",
        "\n",
        "<img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/charts/chart3.png?raw=1\" width=\"1000\"/>\n",
        "\n",
        "Si existe más de una imagen de Sentinel-1 en la subcarpeta *'entrada'*, el usuario puede seleccionar cuál se utilizará para el procesamiento. El subconjunto se genera de acuerdo con el archivo AOI en la subcarpeta *'AOI'*. Si no se proporciona un archivo AOI, un mapa interactivo permite dibujar y descargar el área de interés haciendo clic en el botón *'Exportar'* - dentro del mapa o cargar directamente un archivo AOI almacenado localmente. Posteriormente, se realizan los siguientes pasos de procesamiento:\n",
        "\n",
        "1. ***Aplicar el archivo de órbita***: El archivo de órbita proporciona información precisa sobre la posición y la velocidad del satélite. Con base en esta información, se actualizan los vectores de estado de la órbita en los metadatos del producto. Los archivos de órbita precisos están disponibles de días a semanas después de la generación del producto. Dado que este es un paso de procesamiento opcional, la herramienta continuará el flujo de trabajo en caso de que el archivo de órbita aún no esté disponible para permitir aplicaciones de mapeo rápido.\n",
        "\n",
        "\n",
        "2. ***Eliminación de ruido térmico***: la corrección de ruido térmico se aplica a los productos Sentinel-1 Nivel-1 GRD que aún no se han corregido.\n",
        "\n",
        "\n",
        "3. ***Calibración radiométrica***: El objetivo de esta calibración de SAR es proporcionar imágenes en las que los valores de los píxeles se puedan relacionar directamente con la retrodispersión de la escena de radar. Aunque las imágenes de SAR no calibradas son suficientes para un uso cualitativo, las imágenes de SAR calibradas son esenciales para el uso cuantitativo de los datos de SAR.\n",
        "\n",
        "\n",
        "4. ***Filtrado de puntos***: las imágenes SAR tienen texturas inherentes llamadas puntos que degradan la calidad de la imagen y dificultan la interpretación de las características. Estos puntos son causados por la interferencia aleatoria constructiva y destructiva de las ondas de retorno desfasadas pero coherentes y retro-dispersadas por la dispersión elemental dentro de cada celda de resolución. La reducción de ruido de estos puntos se puede aplicar mediante filtrado espacial o procesamiento multilook. En este paso se utiliza un filtro de tipo Lee con un tamaño de ventana de 5 x 5.\n",
        "\n",
        "\n",
        "5. ***Corrección del terreno***: Debido a las variaciones topográficas de una escena y la inclinación del sensor de satélite, las distancias en las imágenes SAR pueden distorsionarse. Los datos que no se dirijan directamente a la ubicación del nadir del sensor tendrán cierta distorsión. Por lo tanto, las correcciones del terreno están destinadas a compensar estas deformaciones para permitir una representación geométrica realista en la imagen.\n",
        "\n",
        "\n",
        "6. ***Binarización***: para obtener una máscara de inundación binaria, se analiza el histograma para separar el agua de los píxeles que no son de agua. Debido a la geometría lateral de los sensores SAR y la superficie del agua comparativamente lisa, solo una proporción muy pequeña de retrodispersión se refleja en el sensor, lo que genera valores de píxeles comparativamente bajos en el histograma. El umbral utilizado para la separación se calcula automáticamente utilizando las implementaciones de <a href=\"https://scikit-image.org/\"> scikit-image </a> y un uso combinado del <a href = \"https: // doi .org / 10.1111 / j.1749-6632.1965.tb11715.x \"> método mínimo </a> y el <a href =\" https://www.semanticscholar.org/paper/A-threshold-selection-method-from- gray-level-Otsu / 1d4816c612e38dac86f2149af667a5581686cdef? p2df \"> método de Otsu </a>. La capa <a href=\"http://due.esrin.esa.int/page_globcover.php\"> GlobCover </a> de la Agencia Espacial Europea se utiliza para enmascarar los cuerpos de agua permanentes.\n",
        "\n",
        "\n",
        "7. ***Filtrado de manchas***: En este paso se utiliza un filtro de mediana con un tamaño de ventana de 7 x 7."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "q3yEG-4jW3_V"
      },
      "source": [
        "#@title <font color=#1B7192> Click para iniciar </font>  { display-mode: \"form\" }\n",
        "\n",
        "####################################################\n",
        "############# DEFINICIÓN DE FUNSIONES ##############\n",
        "####################################################\n",
        "\n",
        "def applySubset(path):\n",
        "    # establecer la ruta correcta del archivo de entrada y crear el producto S1\n",
        "    if len(files) is 1:\n",
        "        file_path = path\n",
        "    else:\n",
        "        file_path = path.selected\n",
        "    S1_source = snappy.ProductIO.readProduct(file_path)\n",
        "\n",
        "    # leer las coordenadas geográficas de los metadatos de las imágenes Sentinel-1\n",
        "    meta_data = S1_source.getMetadataRoot().getElement('Abstracted_Metadata')\n",
        "    # define el centro del mapa de acuerdo con la imagen Sentinel-1\n",
        "    S1_center = (meta_data.getAttributeDouble('centre_lat'), meta_data.getAttributeDouble('centre_lon'))\n",
        "    # define el polígono que ilustra la imagen de Sentinel-1\n",
        "    polygon_geom = {\n",
        "      \"type\": \"FeatureCollection\",\n",
        "      \"features\":\n",
        "                [{\"type\": \"Feature\",\n",
        "                \"properties\": {},\n",
        "                \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [[[meta_data.getAttributeDouble('first_near_long'), meta_data.getAttributeDouble('first_near_lat')],\n",
        "                                                                [meta_data.getAttributeDouble('last_near_long'), meta_data.getAttributeDouble('last_near_lat')],\n",
        "                                                                [meta_data.getAttributeDouble('last_far_long'), meta_data.getAttributeDouble('last_far_lat')],\n",
        "                                                                [meta_data.getAttributeDouble('first_far_long'), meta_data.getAttributeDouble('first_far_lat')],\n",
        "                                                                [meta_data.getAttributeDouble('first_near_long'), meta_data.getAttributeDouble('first_near_lat')]]]}}]}\n",
        "\n",
        "    # obtener la ruta a las AOI\n",
        "    file = getAOI('%s/AOI' % directory)\n",
        "    # abrir archivo GeoJSON y almacenar los datos\n",
        "    with open(file, 'r') as f:\n",
        "        data_json = json.load(f)\n",
        "    footprint = geojson_to_wkt(data_json)\n",
        "\n",
        "    # crea el mapa\n",
        "    f = folium.Figure(height=500)\n",
        "    m = folium.Map(location = S1_center, zoom_start = 7.5, control_scale=True).add_to(f)\n",
        "    # agregar el mosaico de S1 al mapa\n",
        "    folium.GeoJson(polygon_geom, name='Sentinel-1 tile').add_to(m)\n",
        "    # adiciona las AOI al mapa\n",
        "    folium.GeoJson(file, name='AOI', style_function = lambda x: {'color':'green'}).add_to(m)\n",
        "    # agregar un mapa base personalizado\n",
        "    basemaps['Google Satellite Hybrid'].add_to(m)\n",
        "    # agregar un panel de control de capa al mapa\n",
        "    m.add_child(folium.LayerControl())\n",
        "    # despliega el mapa\n",
        "    updater = display(f, display_id='m')\n",
        "\n",
        "    # Operador de subconjunto o recorte\n",
        "    parameters = snappy.HashMap()\n",
        "    parameters.put('copyMetadata', True)\n",
        "    geom = snappy.WKTReader().read(footprint)\n",
        "    parameters.put('geoRegion', geom)\n",
        "    parameters.put('sourceBands', sourceBands)\n",
        "    S1_crop = snappy.GPF.createProduct('Subset', parameters, S1_source)\n",
        "    # actualiza el estado\n",
        "    print('\\nSubconjunto generado correctamente.\\n', flush=True)\n",
        "\n",
        "    # ejecutar el procesamiento\n",
        "    processing(S1_crop)\n",
        "\n",
        "\n",
        "# calcular y devolve el umbral de entrada para la 'Banda'\n",
        "# SNAP API: https://step.esa.int/docs/v6.0/apidoc/engine/\n",
        "def getThreshold(S1_band):\n",
        "    # leer la banda\n",
        "    w = S1_band.getRasterWidth()\n",
        "    h = S1_band.getRasterHeight()\n",
        "    band_data = np.zeros(w * h, np.float32)\n",
        "    S1_band.readPixels(0, 0, w, h, band_data)\n",
        "    band_data.shape = h * w\n",
        "    # calcular el umbral utilizando el método Otsu\n",
        "    threshold_otsu = skimage.filters.threshold_otsu(band_data)\n",
        "    # calcular el umbral utilizando el método mínimo\n",
        "    threshold_minimum = skimage.filters.threshold_minimum(band_data)\n",
        "    # obtener el número de píxeles para ambos umbrales\n",
        "    numPixOtsu = len(band_data[abs(band_data - threshold_otsu) < 0.1])\n",
        "    numPixMinimum = len(band_data[abs(band_data - threshold_minimum) < 0.1])\n",
        "\n",
        "    # si el número de píxeles en el umbral mínimo es inferior al 0,1% del número de píxeles en el umbral de Otsu\n",
        "    if abs(numPixMinimum/numPixOtsu) < 0.001:\n",
        "        # ajustar los datos de la banda de acuerdo a:\n",
        "        if threshold_otsu < threshold_minimum:\n",
        "            band_data = band_data[band_data < threshold_minimum]\n",
        "            threshold_minimum = skimage.filters.threshold_minimum(band_data)\n",
        "        else:\n",
        "            band_data = band_data[band_data > threshold_minimum]\n",
        "            threshold_minimum = skimage.filters.threshold_minimum(band_data)\n",
        "        numPixMinimum = len(band_data[abs(band_data - threshold_minimum) < 0.1])\n",
        "    # comprobar el umbral final\n",
        "    if abs(numPixMinimum/numPixOtsu) < 0.001:\n",
        "        threshold = threshold_otsu\n",
        "    else:\n",
        "        threshold = threshold_minimum\n",
        "\n",
        "    return threshold\n",
        "\n",
        "\n",
        "# calcula la máscara binaria o 'Producto' con respecto a la expresión en la matriz de cadenas\n",
        "def binarization(S1_product, expressions):\n",
        "\n",
        "    BandDescriptor = jpy.get_type('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor')\n",
        "    targetBands = jpy.array('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor', len(expressions))\n",
        "\n",
        "    # bucle a través de bandas\n",
        "    for i in range(len(expressions)):\n",
        "        targetBand = BandDescriptor()\n",
        "        targetBand.name = '%s' % S1_product.getBandNames()[i]\n",
        "        targetBand.type = 'float32'\n",
        "        targetBand.expression = expressions[i]\n",
        "        targetBands[i] = targetBand\n",
        "    \n",
        "    parameters = snappy.HashMap()\n",
        "    parameters.put('targetBands', targetBands)    \n",
        "    mask = snappy.GPF.createProduct('BandMaths', parameters, S1_product)\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "# pasos de procesamiento\n",
        "def processing(S1_crop):\n",
        "    # aplica el archivo de órbita\n",
        "    print('1. Aplica el archivo de orbita:          ', end='', flush=True)\n",
        "    start_time = time.time()\n",
        "    parameters = snappy.HashMap()\n",
        "    # Continuar con el cálculo en caso de que aún no haya ningún archivo de órbita disponible.\n",
        "    parameters.put('continueOnFail', True)\n",
        "    S1_Orb = snappy.GPF.createProduct('Apply-Orbit-File', parameters, S1_crop)\n",
        "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
        "\n",
        "    # eliminación de ruido térmico\n",
        "    print('2. Eliminación de ruido térmico:         ', end='', flush=True)\n",
        "    start_time = time.time()\n",
        "    parameters = snappy.HashMap()\n",
        "    parameters.put('removeThermalNoise', True)\n",
        "    S1_Thm = snappy.GPF.createProduct('ThermalNoiseRemoval', parameters, S1_Orb)\n",
        "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
        "\n",
        "    # Operador de calibración\n",
        "    print('3. Calibración radiométrica:             ', end='', flush=True)\n",
        "    start_time = time.time()\n",
        "    parameters = snappy.HashMap()\n",
        "    parameters.put('outputSigmaBand', True)\n",
        "    S1_Cal = snappy.GPF.createProduct('Calibration', parameters, S1_Thm)\n",
        "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
        "\n",
        "    # Operador de filtro de manchas\n",
        "    print('4. Filtrado de ruido (Speckle):          ', end='', flush=True)\n",
        "    start_time = time.time()\n",
        "    parameters = snappy.HashMap()\n",
        "    parameters.put('filter', 'Lee')\n",
        "    parameters.put('filterSizeX', 5)\n",
        "    parameters.put('filterSizeY', 5)\n",
        "    S1_Spk = snappy.GPF.createProduct('Speckle-Filter', parameters, S1_Cal)\n",
        "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
        "\n",
        "    # Conversión del operador lineal a db\n",
        "    S1_Spk_db = snappy.GPF.createProduct('LinearToFromdB', snappy.HashMap(), S1_Spk)\n",
        "\n",
        "    # Operador de la corrección de terreno\n",
        "    print('5. Corrección Topográfica:               ', end='', flush=True)\n",
        "    parameters = snappy.HashMap()\n",
        "    parameters.put('demName', 'SRTM 1Sec HGT')\n",
        "    parameters.put('demResamplingMethod', 'BILINEAR_INTERPOLATION')\n",
        "    parameters.put('imgResamplingMethod', 'NEAREST_NEIGHBOUR')\n",
        "    parameters.put('pixelSpacingInMeter', 10.0)\n",
        "    parameters.put('nodataValueAtSea', False)\n",
        "    parameters.put('saveSelectedSourceBand', True)\n",
        "    S1_TC = snappy.GPF.createProduct('Terrain-Correction', parameters, S1_Spk_db)\n",
        "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
        "\n",
        "    # Binarización\n",
        "    print('6. Binarización:                         ', end='', flush=True)\n",
        "    start_time = time.time()\n",
        "    # adiciona la capa del GlobCover \n",
        "    parameters = snappy.HashMap()\n",
        "    parameters.put('landCoverNames', 'GlobCover')\n",
        "    GlobCover = snappy.GPF.createProduct('AddLandCover', parameters, S1_TC)\n",
        "    # matriz de cadena vacía para expresiones matemáticas de banda de binarización\n",
        "    expressions = ['' for i in range(S1_TC.getNumBands())]\n",
        "    # matriz vacía para umbral (s)\n",
        "    thresholds = np.zeros(S1_TC.getNumBands())\n",
        "    # bucle a través de las bandas\n",
        "    for i in range(S1_TC.getNumBands()):\n",
        "        # calcular el umbral de la banda y almacenarlo en una matriz flotante\n",
        "        # utilice el producto S1_Spk_db por motivos de rendimiento. S1_TC provoca valores 0\n",
        "        # que distorsionan el histograma y, por lo tanto, el resultado del umbral\n",
        "        thresholds[i] = getThreshold(S1_Spk_db.getBandAt(i))\n",
        "        # formular la expresión según el umbral y almacenarla en una matriz de cadenas\n",
        "        expressions[i] = 'if (%s < %s && land_cover_GlobCover != 210) then 1 else NaN' % (S1_TC.getBandNames()[i], thresholds[i])\n",
        "    # hacer binarización\n",
        "    S1_floodMask = binarization(GlobCover, expressions)\n",
        "    print('--- %.2f seconds ---' % (time.time() - start_time), flush=True)\n",
        "\n",
        "    # Operador de filtro de manchas o puntos\n",
        "    print('7. Filtrado de ruido (Speckle):          ', end='', flush=True)\n",
        "    start_time = time.time()\n",
        "    parameters = snappy.HashMap()\n",
        "    parameters.put('filter', 'Median')\n",
        "    parameters.put('filterSizeX', 5)\n",
        "    parameters.put('filterSizeY', 5)\n",
        "    # definir la máscara de inundación como global para un acceso posterior\n",
        "    global S1_floodMask_Spk\n",
        "    S1_floodMask_Spk = snappy.GPF.createProduct('Speckle-Filter', parameters, S1_floodMask)\n",
        "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
        "\n",
        "    # salida\n",
        "    if PlotResults:\n",
        "        print('8. Graficar :                            ', end='', flush=True)\n",
        "        start_time = time.time()\n",
        "        for i in range(S1_TC.getNumBands()):\n",
        "            plotBand(S1_TC.getBandAt(i), thresholds[i])\n",
        "        print('--- %.2f seconds ---' % (time.time() - start_time), flush=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "####################################################\n",
        "###################### CÓDIGO ######################\n",
        "####################################################\n",
        "\n",
        "# filtrar la(s) polarización(es) requerida(s) y establecer el nombre del archivo de salida en consecuencia\n",
        "if Polarisation == 'ambas':\n",
        "    sourceBands = 'Amplitude_VH,Intensity_VH,Amplitude_VV,Intensity_VV'\n",
        "    output_extensions   = 'processed_VHVV'\n",
        "elif Polarisation == 'VH':\n",
        "    sourceBands = 'Amplitude_VH,Intensity_VH'\n",
        "    output_extensions   = 'processed_VH'\n",
        "elif Polarisation == 'VV':\n",
        "    sourceBands = 'Amplitude_VV,Intensity_VV'\n",
        "    output_extensions   = 'processed_VV'\n",
        "\n",
        "# ruta del archivo de entrada .zip de Sentinel-1\n",
        "input_path = os.path.join(directory, 'entrada')\n",
        "# matriz de cadena vacía para almacenar archivos Sentinel-1 en la subcarpeta 'entrada'\n",
        "files = []\n",
        "# agregar archivos a la lista\n",
        "for file in glob.glob1(input_path, '*.zip'):\n",
        "    files.append(file)\n",
        "# seleccione el archivo de entrada y comience a procesar si solo hay un archivo Sentinel-1 disponible\n",
        "if len(files) == 1:\n",
        "    input_name = files[0]\n",
        "    print('Seleccionado:  %s\\n' % input_name, flush=True)\n",
        "    # aplicar subconjunto de acuerdo con los datos JSON\n",
        "    applySubset('%s/%s' % (input_path, input_name))\n",
        "# abrir la caja de diálogo para seleccionar el archivo de entrada si hay más o menos de uno disponible\n",
        "else:\n",
        "    print('Se ha encontrado más de un archivo Sentinel-1. Por favor seleccione.', flush=True)\n",
        "    fc = FileChooser(input_path)\n",
        "    fc.filter_pattern = '*.zip'\n",
        "    fc.register_callback(applySubset)\n",
        "    display(fc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MavzlDEFW3_W"
      },
      "source": [
        "## Exportar Datos\n",
        "\n",
        "<img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/charts/chart4.png?raw=1\" width=\"1000\"/>\n",
        "\n",
        "La máscara de inundación procesada se exporta como un GeoTIFF, SHP, KML y GeoJSON y se almacena en la subcarpeta *'salida'*. Un mapa interactivo muestra la máscara de inundación."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [
          0
        ],
        "id": "og4yIuW3W3_W"
      },
      "source": [
        "#@title <font color=#1B7192> Click para iniciar </font>  { display-mode: \"form\" }\n",
        "\n",
        "####################################################\n",
        "####################### CODE #######################\n",
        "####################################################\n",
        "\n",
        "print('Exportando...\\n', flush=True)\n",
        "# compruebe si existen carpetas de salida, si no crea las carpetas\n",
        "output_path = os.path.join(directory, 'salida')\n",
        "if not os.path.isdir(output_path):\n",
        "    os.mkdir(output_path)\n",
        "GeoTIFF_path = os.path.join(output_path, 'GeoTIFF')\n",
        "if not os.path.isdir(GeoTIFF_path):\n",
        "    os.mkdir(GeoTIFF_path)\n",
        "SHP_path = os.path.join(output_path, 'SHP')\n",
        "if not os.path.isdir(SHP_path):\n",
        "    os.mkdir(SHP_path)\n",
        "KML_path = os.path.join(output_path, 'KML')\n",
        "if not os.path.isdir(KML_path):\n",
        "    os.mkdir(KML_path)\n",
        "GeoJSON_path = os.path.join(output_path, 'GeoJSON')\n",
        "if not os.path.isdir(GeoJSON_path):\n",
        "    os.mkdir(GeoJSON_path)\n",
        "# obtener el nombre del archivo si se utilizó el selector de archivos\n",
        "if len(files) is not 1: input_name = fc.selected_filename\n",
        "\n",
        "# escribir el archivo de salida como GeoTIFF\n",
        "print('1. GeoTIFF:                   ', end='', flush=True)\n",
        "start_time = time.time()\n",
        "snappy.ProductIO.writeProduct(S1_floodMask_Spk, '%s/%s_%s' % (GeoTIFF_path, os.path.splitext(input_name)[0], output_extensions), 'GeoTIFF')\n",
        "print('--- %.2f seconds ---' % (time.time() - start_time), flush=True)\n",
        "\n",
        "# convertir el GeoTIFF a SHP\n",
        "print('2. SHP:                       ', end='', flush=True)\n",
        "start_time = time.time()\n",
        "# permitir que GDAL lance excepciones de Python\n",
        "gdal.UseExceptions()\n",
        "open_image = gdal.Open('%s/%s_%s.tif' % (GeoTIFF_path, os.path.splitext(input_name)[0], output_extensions))\n",
        "srs = osr.SpatialReference()\n",
        "srs.ImportFromWkt(open_image.GetProjectionRef())\n",
        "shp_driver = ogr.GetDriverByName('ESRI Shapefile')\n",
        "# matriz de cadena vacía para las bandas en GeoTIFF\n",
        "output_shp = ['' for i in range(open_image.RasterCount)]\n",
        "if open_image.RasterCount == 1:\n",
        "    output_shp[0] = '%s/%s_processed_%s' % (SHP_path, os.path.splitext(input_name)[0], Polarisation)\n",
        "else:\n",
        "    VH_SHP_path = os.path.join(SHP_path, 'VH')\n",
        "    if not os.path.isdir(VH_SHP_path):\n",
        "        os.mkdir(VH_SHP_path)\n",
        "    VV_SHP_path = os.path.join(SHP_path, 'VV')\n",
        "    if not os.path.isdir(VV_SHP_path):\n",
        "        os.mkdir(VV_SHP_path)\n",
        "    output_shp[0] = '%s/%s_processed_VH' % (VH_SHP_path, os.path.splitext(input_name)[0])\n",
        "    output_shp[1] = '%s/%s_processed_VV' % (VV_SHP_path, os.path.splitext(input_name)[0])\n",
        "# bucles a través de las bandas en GeoTIFF\n",
        "for i in range(open_image.RasterCount):\n",
        "    input_band = open_image.GetRasterBand(i+1)\n",
        "    output_shapefile = shp_driver.CreateDataSource(output_shp[i] + '.shp')\n",
        "    new_shapefile = output_shapefile.CreateLayer(output_shp[i], srs=srs)\n",
        "    new_shapefile.CreateField(ogr.FieldDefn('DN', ogr.OFTInteger))\n",
        "    gdal.Polygonize(input_band, input_band.GetMaskBand(), new_shapefile, 0, [], callback=None)\n",
        "    # filtra los atributos con valores distintos de 1 (debe ser NaN o el valor respectivo)\n",
        "    new_shapefile.SetAttributeFilter('DN != 1')\n",
        "    for feat in new_shapefile:\n",
        "        new_shapefile.DeleteFeature(feat.GetFID())\n",
        "    new_shapefile.SyncToDisk()\n",
        "print('--- %.2f seconds ---' % (time.time() - start_time), flush=True)\n",
        "\n",
        "# convertir de SHP a KML\n",
        "print('3. KML:                       ', end='', flush=True)\n",
        "start_time = time.time()\n",
        "if open_image.RasterCount == 1:\n",
        "    shp_file = gdal.OpenEx('%s/%s_processed_%s.shp' % (SHP_path, os.path.splitext(input_name)[0], Polarisation))\n",
        "    ds = gdal.VectorTranslate('%s/%s_processed_%s.kml' % (KML_path, os.path.splitext(input_name)[0], Polarisation), shp_file, format='KML')\n",
        "    del ds\n",
        "else:\n",
        "    shp_file_VH = gdal.OpenEx('%s/%s_processed_VH.shp' % (VH_SHP_path, os.path.splitext(input_name)[0]))\n",
        "    ds_VH = gdal.VectorTranslate('%s/%s_processed_VH.kml' % (KML_path, os.path.splitext(input_name)[0]), shp_file_VH, format='KML')\n",
        "    del ds_VH\n",
        "    shp_file_VV = gdal.OpenEx('%s/%s_processed_VV.shp' % (VV_SHP_path, os.path.splitext(input_name)[0]))\n",
        "    ds_VV = gdal.VectorTranslate('%s/%s_processed_VV.kml' % (KML_path, os.path.splitext(input_name)[0]), shp_file_VV, format='KML')\n",
        "    del ds_VV\n",
        "print('--- %.2f seconds ---' % (time.time() - start_time), flush=True)\n",
        "\n",
        "# convertir de SHP a GeoJSON\n",
        "print('4. GeoJSON:                   ', end='', flush=True)\n",
        "start_time = time.time()\n",
        "if open_image.RasterCount == 1:\n",
        "    shp_file = geopandas.read_file('%s/%s_processed_%s.shp' % (SHP_path, os.path.splitext(input_name)[0], Polarisation))\n",
        "    shp_file.to_file('%s/%s_processed_%s.json' % (GeoJSON_path, os.path.splitext(input_name)[0], Polarisation), driver='GeoJSON')\n",
        "else:\n",
        "    shp_file_VH = geopandas.read_file('%s/%s_processed_VH.shp' % (VH_SHP_path, os.path.splitext(input_name)[0]))\n",
        "    shp_file_VH.to_file('%s/%s_processed_VH.json' % (GeoJSON_path, os.path.splitext(input_name)[0]), driver='GeoJSON')    \n",
        "    shp_file_VV = geopandas.read_file('%s/%s_processed_VV.shp' % (VV_SHP_path, os.path.splitext(input_name)[0]))\n",
        "    shp_file_VV.to_file('%s/%s_processed_VV.json' % (GeoJSON_path, os.path.splitext(input_name)[0]), driver='GeoJSON')\n",
        "print('--- %.2f seconds ---\\n' % (time.time() - start_time), flush=True)\n",
        "print('Archivos almacenados correctamente en %s.\\n' % output_path, flush=True)\n",
        "\n",
        "# gráfica los resultados\n",
        "meta_data = S1_floodMask_Spk.getMetadataRoot().getElement('Abstracted_Metadata')\n",
        "S1_center = (meta_data.getAttributeDouble('centre_lat'), meta_data.getAttributeDouble('centre_lon'))\n",
        "f = folium.Figure(height=500)\n",
        "results_map = folium.Map(location = S1_center, zoom_start = 9, control_scale = True).add_to(f)\n",
        "if open_image.RasterCount == 1:\n",
        "    file = '%s/%s_processed_%s.json' % (GeoJSON_path, os.path.splitext(input_name)[0], Polarisation)\n",
        "    folium.GeoJson(file, name='Flood Mask %s' % Polarisation, style_function = lambda x: {'color':'blue', 'opacity':'1', 'fillColor':'blue', 'fillOpacity':'1', 'weight':'0.8'}).add_to(results_map)\n",
        "else:\n",
        "    file_VV = '%s/%s_processed_VV.json' % (GeoJSON_path, os.path.splitext(input_name)[0])\n",
        "    folium.GeoJson(file_VV, name='Flood Mask VV', style_function = lambda x: {'color':'red', 'opacity':'1', 'fillColor':'red', 'fillOpacity':'1', 'weight':'0.8'}).add_to(results_map)\n",
        "    file_VH = '%s/%s_processed_VH.json' % (GeoJSON_path, os.path.splitext(input_name)[0])\n",
        "    folium.GeoJson(file_VH, name='Flood Mask VH', style_function = lambda x: {'color':'blue', 'opacity':'1', 'fillColor':'blue', 'fillOpacity':'1', 'weight':'0.8'}).add_to(results_map)\n",
        "# agregar un mapa base personalizado\n",
        "basemaps['Google Satellite Hybrid'].add_to(results_map)\n",
        "# agregar un panel de control de capa al mapa\n",
        "results_map.add_child(folium.LayerControl(collapsed=False))\n",
        "display(f)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}