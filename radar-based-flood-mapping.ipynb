{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/header.png?raw=1\" width=\"1000\"/>\n",
    "\n",
    "\n",
    "# Mapeo de inundaciones mediante imágenes de radar Sentinel-1\n",
    "\n",
    "<img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/example.png?raw=1\" width=\"1000\"/>\n",
    "\n",
    "***\n",
    "\n",
    "El objetivo de esta [práctica recomendada](https://un-spider.org/advisory-support/recommended-practices) es determinar la extensión de las áreas inundadas. El uso de imágenes satelitales de radar de apertura sintética (SAR) para el mapeo de la extensión de las inundaciones constituye una solución viable con un procesamiento rápido de imágenes, que proporciona información de inundaciones casi en tiempo real a las agencias de ayuda para apoyar la acción humanitaria. La alta confiabilidad de los datos, así como la ausencia de restricciones geográficas, como la accesibilidad del sitio, enfatizan el potencial de esta tecnología.\n",
    "\n",
    "Este cuaderno de Jupyter Notebook cubre toda la cadena de procesamiento desde la consulta de datos, la descarga, hasta la exportación de un producto final de máscara de inundación mediante la utilización de imágenes de acceso libre SAR Sentinel-1. El flujo de trabajo de la herramienta sigue la práctica recomendada de ONU-SPIDER sobre la [cartografía de inundaciones basada en radar](https://un-spider.org/advisory-support/recommended-practices/recommended-practice-radar-based-flood-mapping), tal y como se ilustra en el siguiente cuadro. Después de ingresar las especificaciones del usuario, los datos de Sentinel-1 se pueden descargar directamente desde el <a href=\"https://scihub.copernicus.eu/\"> Copernicus Open Access Hub </a>. Posteriormente, los datos se procesan y almacenan en una variedad de formatos de salida.\n",
    "\n",
    "<img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/charts/chart0.png?raw=1\" width=\"1000\"/>\n",
    "\n",
    "***\n",
    "\n",
    "***Estructura del archivo***  \n",
    "El archivo Jupyter Notebook constituye el directorio de origen. Los datos adicionales están contenidos en subcarpetas. Las imágenes de Sentinel-1 deben almacenarse en una subcarpeta llamada *'entrada'*. Si no se proporciona ninguna imagen, la subcarpeta se creará automáticamente al acceder y descargar datos a través de la herramienta<a href=\"https://scihub.copernicus.eu/\"> Copernicus Open Access Hub </a>. Si hay un archivo de área de interés (AOI) disponible (formatos compatibles: GeoJSON, SHP, KML, KMZ), debe colocarse en una subcarpeta llamada *'AOI'*. Si no hay ninguno, un mapa interactivo permitirá dibujar manualmente el área de interés. Por razones de selección automática de archivos, se recomienda colocar solo un archivo AOI en la carpeta correspondiente. Sin embargo, si existen varios archivos, los archivos GeoJSON tendrán prioridad, seguidos de SHP, KML y KMZ. Los datos procesados se almacenan en una subcarpeta llamada * 'salida' *.  \n",
    "Para ejecutar la herramienta sin interacción del usuario, todas las entradas deben estar claramente definidas. Esto significa que la subcarpeta *'input'* debe incluir una sola imagen Sentinel-1 y la subcarpeta *'AOI'* un solo archivo de área de interés AOI. Todos los demás escenarios requieren interacción manual, como descargar datos o definir un AOI. \n",
    "\n",
    "***Limitaciones***  \n",
    "Existen limitaciones a la hora de detectar vegetación inundada e inundaciones en áreas urbanas debido a la retrodispersión de doble rebote. Si el agua y el no agua se distribuyen de manera muy desigual en la imagen, es posible que el histograma no tenga un mínimo local claro, lo que da lugar a resultados incorrectos en el proceso de binarización automática.\n",
    "\n",
    "\n",
    "***Importante***\n",
    "El cuaderno de Jupyter Notebook aprovecha la API <a href=\"https://step.esa.int/docs/v6.0/apidoc/engine/\"> ESA SNAP </a> y requiere la instalación de la <i> ágil interfaz </i> SNAP-Python. Haga clic <a href=\"https://senbox.atlassian.net/wiki/spaces/SNAP/pages/24051781/Using+SNAP+in+your+Python+programs\"> aquí </a> para obtener más información. Además, las <a href=\"https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/install.html\"> extensiones de Jupyter Notebook </a> *Codefolding*, *ExecuteTime* y *Table of Contents (2)* se utilizan para un mejor rendimiento.\n",
    "\n",
    "***\n",
    "\n",
    "## Entradas de Usuario\n",
    "\n",
    "<img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/charts/chart1.png?raw=1\" width=\"1000\"/>\n",
    "\n",
    "Especifique en la celda de código a continuación **i)** el tipo de polarización que se procesará, **ii)** si los datos se descargarán del <a href=\"https://scihub.copernicus.eu/\"> Copernicus Open Access Hub </a> con el respectivo período de detección y detalles de inicio de sesión, y **iii)** si los resultados intermedios deben ser graficados durante el proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polarizaciones a procesar\n",
    "polarisations = 'VH'                              # 'VH', 'VV', 'ambas'\n",
    "\n",
    "# descargar imagen del Copernicus Open Access Hub\n",
    "download = {\n",
    "    'imageDownload'     : True,                   # 'True', 'False'\n",
    "    'period_start'      : [2021, 1, 1],           # formato: [año, mes, día]\n",
    "    'period_stop'       : [2021, 1, 8],           # formato: [año, mes, día]\n",
    "    'username'          : 'username',             # nombre de ususario\n",
    "    'password'          : 'password'              # contraseña\n",
    "}\n",
    "\n",
    "# mostar resultados intermedios si se selecciona 'True'\n",
    "plotResoluts = True                               # 'True', 'False'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inicialización\n",
    "\n",
    "Esta sección carga los módulos de Python relevantes para el siguiente análisis e inicializa las funcionalidades básicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     37,
     85
    ]
   },
   "outputs": [],
   "source": [
    "# Click para iniciar\n",
    "\n",
    "#####################################################\n",
    "###################### IMPORTAR #####################\n",
    "#####################################################\n",
    "\n",
    "# MODULO                                      # DESCRIPCIÓN\n",
    "import sys\n",
    "import matplotlib.pyplot as plt               # crear visualizaciones\n",
    "import numpy as np                            # Computación científica\n",
    "import json                                   # codificación y decodifiación JSON \n",
    "import glob                                   # acceso de datos\n",
    "import os                                     # acceso de datoss\n",
    "import ipywidgets                             # controles interactivos de la UI \n",
    "import time                                   # tiempo de evaluación \n",
    "import shutil                                 # operaciones de archivo\n",
    "import ipyleaflet                             # visualización\n",
    "import geopandas                              # manipulación y análisis de datos\n",
    "import snappy                                 # interfase SNAP Python \n",
    "import jpy                                    # puente Python-Java \n",
    "import skimage.filters                        # cálculo de umbral\n",
    "import functools                              # funciones y operaciones de orden superior\n",
    "from ipyfilechooser import FileChooser        # widget selector de archivos\n",
    "from sentinelsat.sentinel import SentinelAPI, read_geojson, geojson_to_wkt  # interface para el Open Access Hub\n",
    "from datetime import date                     # fechas, horas e intervalos\n",
    "from IPython.display import display           # visualización\n",
    "from osgeo import ogr, gdal, osr              # conversión de datos\n",
    "from zipfile import ZipFile                   # gestión de archivos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################\n",
    "############## DEFINICIÓN DE FUNSIONES #############\n",
    "####################################################\n",
    "\n",
    "# Esta función busca el archivo de AOI, se convierte a GeoJSON si no se proporciona uno y devuelve GeoJSON\n",
    "def readJSONFromAOI(path):\n",
    "    # busque el archivo GeoJSON en la subcarpeta 'AOI'\n",
    "    if len(glob.glob('%s/*.geojson' % path)) == 1:\n",
    "        file = glob.glob('%s/*.geojson' % path)[0]\n",
    "    elif len(glob.glob('%s/*.json' % path)) == 1:\n",
    "        file = glob.glob('%s/*.json' % path)[0]\n",
    "\n",
    "    # convertir SHP a GeoJSON si no se proporciona un JSON\n",
    "    elif len(glob.glob('%s/*.shp' % path)) == 1:\n",
    "        file_name = os.path.splitext(glob.glob('%s/*.shp' % path)[0])[0].split('/')[-1]\n",
    "        shp_file = geopandas.read_file(glob.glob('%s/*.shp' % path)[0])\n",
    "        shp_file.to_file('%s/%s.json' % (path, file_name), driver='GeoJSON')\n",
    "        file = glob.glob('%s/*.json' % path)[0]\n",
    "\n",
    "    # convertir KML a GeoJSON si no se proporciona un JSON o SHP\n",
    "    elif len(glob.glob('%s/*.kml' % path)) == 1:\n",
    "        file_name = os.path.splitext(glob.glob('%s/*.kml' % path)[0])[0].split('/')[-1]\n",
    "        kml_file = gdal.OpenEx(glob.glob('%s/*.kml' % path)[0])\n",
    "        ds = gdal.VectorTranslate('%s/%s.json' % (path, file_name), kml_file, format='GeoJSON')\n",
    "        del ds\n",
    "        file = glob.glob('%s/*.json' % path)[0]\n",
    "\n",
    "    # convertir KMZ a JSON si no se proporciona un JSON, SHP o KML\n",
    "    elif len(glob.glob('%s/*.kmz' % path)) == 1:\n",
    "        # abrir archivo KMZ y extraer los datos\n",
    "        with ZipFile(glob.glob('%s/*.kmz' % path)[0], 'r') as kmz:\n",
    "            folder = os.path.splitext(glob.glob('%s/*.kmz' % path)[0])[0]\n",
    "            kmz.extractall(folder)\n",
    "        # convertir KML a GeoJSON si la carpeta extraída contiene un archivo KML\n",
    "        if len(glob.glob('%s/*.kml' % folder)) == 1:\n",
    "            kml_file = gdal.OpenEx(glob.glob('%s/*.kml' % folder)[0])\n",
    "            ds = gdal.VectorTranslate('%s/%s.json' % (path, folder.split('/')[-1]), kml_file, format='GeoJSON')\n",
    "            del ds\n",
    "            file = glob.glob('%s/*.json' % path)[0]\n",
    "            # remove unzipped KMZ directory and data\n",
    "            shutil.rmtree(folder)\n",
    "    # eliminar el directorio y los datos del KMZ descomprimidos\n",
    "    else:\n",
    "        raise FileNotFoundError\n",
    "\n",
    "    # abrir archivo JSON y almacenar los datos\n",
    "    with open(file, 'r') as f:\n",
    "        data_json = json.load(f)\n",
    "\n",
    "    return data_json\n",
    "\n",
    "# gráficar la banda e histograma de entrada y un umbral de tipo de 'Banda'\n",
    "# SNAP API: https://step.esa.int/docs/v6.0/apidoc/engine/\n",
    "def plotBand(band, threshold, binary=False):\n",
    "    # realce de color\n",
    "    vmin, vmax = 0, 1\n",
    "    # leer los valores de pixeles\n",
    "    w = band.getRasterWidth()\n",
    "    h = band.getRasterHeight()\n",
    "    band_data = np.zeros(w * h, np.float32)\n",
    "    band.readPixels(0, 0, w, h, band_data)\n",
    "    band_data.shape = h, w\n",
    "    # realce de color\n",
    "    if binary:\n",
    "        cmap = plt.get_cmap('binary')\n",
    "    else:\n",
    "        vmin = np.percentile(band_data, 2.5)\n",
    "        vmax = np.percentile(band_data, 97.5)\n",
    "        cmap = plt.get_cmap('gray')\n",
    "    # gráficar la banda\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(16,6))\n",
    "    ax1.imshow(band_data, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    ax1.set_title(band.getName())\n",
    "    # gráficar el histograma\n",
    "    band_data.shape = h * w \n",
    "    ax2.hist(np.asarray(band_data[band_data != 0], dtype='float'), bins=2048)\n",
    "    ax2.axvline(x=threshold, color='r')\n",
    "    ax2.set_title('Histogram: %s' % band.getName())\n",
    "    \n",
    "    for ax in fig.get_axes():\n",
    "        ax.label_outer()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################\n",
    "###################### CÓDIGO ######################\n",
    "####################################################\n",
    "        \n",
    "# obtener el directorio de trabajo actual\n",
    "directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descarga de Imagen\n",
    "\n",
    "<img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/charts/chart2.png?raw=1\" width=\"1000\"/>\n",
    "\n",
    "Esta sección permite el acceso y la descarga de datos interactivos desde el <a href=\"https://scihub.copernicus.eu/\"> Copernicus Open Access Hub </a>. Si se proporciona un archivo AOI en la subcarpeta *'AOI'*, la herramienta buscará y muestrará las imágenes Sentinel-1 disponibles. Si no se proporciona un archivo AOI, la barra de búsqueda en el lado izquierdo del mapa interactivo se puede utilizar para encontrar la región deseada. A continuación, el archivo AOI se puede seleccionar y editar manualmente mediante la herramienta de dibujo. Al hacer clic en el botón Buscar debajo del mapa, se cargarán las imágenes disponibles. Si se extraen varias AOI, solo se considera la última. Al pasar el cursor sobre una imagen de Sentinel-1, se muestran el índice de mosaico y la fecha de ingestión. La siguiente tabla resume la información sobre todos los mosaicos disponibles y permite la descarga. Los datos se almacenan en la subcarpeta *'entrada'* creada automáticamente. Open Access Hub mantiene un archivo en línea de al menos el último año de productos para su descarga inmediata. El acceso a productos anteriores que ya no están disponibles en línea activará automáticamente la recuperación de los archivos a largo plazo. La descarga real puede ser iniciada por el usuario una vez que se restauran los datos (dentro de las 24 horas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7,
     57,
     65,
     79
    ]
   },
   "outputs": [],
   "source": [
    "# Click para iniciar\n",
    "\n",
    "####################################################\n",
    "############# DEFINICIÓN DE LA FUNCIÓN #############\n",
    "####################################################\n",
    "\n",
    "# buscar y mostrar los mosaicos de Sentinel-1 disponibles\n",
    "def queri(footprint):\n",
    "    # imprime el estado\n",
    "    print('Loading...', flush=True)\n",
    "    # buscar productos en el Copernicus Open Access Hub con respecto a la zona de entrada y el período de detección\n",
    "    try:\n",
    "        products = api.query(footprint,\n",
    "                             date = (date(download['period_start'][0], download['period_start'][1], download['period_start'][2]),\n",
    "                                     date(download['period_stop'][0], download['period_stop'][1], download['period_stop'][2])),\n",
    "                             platformname = 'Sentinel-1',\n",
    "                             producttype = 'GRD')\n",
    "        print('Successfully connected to Copernicus Open Access Hub.\\n', flush=True)\n",
    "    except:\n",
    "        sys.exit('\\nLogin data not valid. Please change username and/or password.')\n",
    "    # convierte a GeoJSON para graficar\n",
    "    products_json = api.to_geojson(products)\n",
    "    # generar una advertencia de que no hay imagen disponible en un período de detección dado\n",
    "    if not products_json['features']:\n",
    "        sys.exit('\\nNo Sentinel-1 images available. Please change sensing period in user input section.')\n",
    "    # convertir a un dataframe para visualización de tablas\n",
    "    products_df = api.to_dataframe(products).sort_values('ingestiondate', ascending=[False])\n",
    "    # adicionar un índice al dataframe\n",
    "    indices = []\n",
    "    for i in range (1, len(products_df.index)+1):\n",
    "        indices.append('Tile %d' % i)\n",
    "        products_json.features[i-1].properties['index'] = ' Tile %d' % i\n",
    "    products_df.insert(0, 'index', indices, True) \n",
    "    # graficar los mosaicos de Sentinel-1 disponibles\n",
    "    geo_json = ipyleaflet.GeoJSON(data = products_json,\n",
    "                                  name = 'S1 tiles',\n",
    "                                  style = {'color' : 'royalblue'},\n",
    "                                  hover_style = {'fillOpacity' : 0.4})\n",
    "    download_map.add_layer(geo_json)\n",
    "    # llamar a la función click_handler cuando el usuario hace clic en el mosaico de Sentinel-1\n",
    "    tile_ID = geo_json.on_hover(hover_handler)\n",
    "    # imprimir la tabla con botones de descarga\n",
    "    grid = ipywidgets.GridspecLayout(len(products_df.index)+1, 5, height='250px')\n",
    "    grid[0,0] = ipywidgets.HTML('<h4>Index</h4>')\n",
    "    grid[0,1] = ipywidgets.HTML('<h4>Ingestion Date</h4>')\n",
    "    grid[0,2] = ipywidgets.HTML('<h4>Polarisation</h4>')\n",
    "    grid[0,3] = ipywidgets.HTML('<h4>Size</h4>')\n",
    "    for i in range(len(products_df.index)):\n",
    "        grid[i+1,0] = ipywidgets.Label(products_df['index'][i])\n",
    "        grid[i+1,1] = ipywidgets.Label(str(products_df['ingestiondate'][i]))\n",
    "        grid[i+1,2] = ipywidgets.Label(products_df['polarisationmode'][i])\n",
    "        grid[i+1,3] = ipywidgets.Label(products_df['size'][i])\n",
    "        grid[i+1,4] = ipywidgets.Button(description = 'Download')\n",
    "        grid[i+1,4].on_click(functools.partial(on_downloadButton_clicked, tile_id=products_df.values[i][-1]))\n",
    "    display(grid)\n",
    "    \n",
    "# muestra el índice del producto y la fecha de ingestión en el elemento HTML al pasar el cursor sobre el mosaico de Sentinel-1\n",
    "def hover_handler(feature, **kwargs):\n",
    "    # restablecer el widget HTML y establecer nuevos valores\n",
    "    html.value = '''\n",
    "    Index: {}<br/>\n",
    "    <small>Ingestion Date: {}</small>\n",
    "    '''.format(feature['properties']['index'], feature['properties']['ingestiondate'])\n",
    "\n",
    "# buscar mosaicos de Sentinel-1 disponibles con respecto a AOI\n",
    "def on_searchButton_clicked(b):\n",
    "    # reenfoque del mapa para cubrir mosaicos de Sentinel-1\n",
    "    download_map.zoom = 6.5\n",
    "    # crear el elemento WKT con coordenadas geográficas del AOI\n",
    "    coordinates = draw_control.last_draw['geometry']['coordinates'][0]\n",
    "    lng1, lat1 = coordinates[0][0], coordinates[0][1]\n",
    "    lng2, lat2 = coordinates[1][0], coordinates[1][1]\n",
    "    lng3, lat3 = coordinates[2][0], coordinates[2][1]\n",
    "    lng4, lat4 = coordinates[3][0], coordinates[3][1]\n",
    "    footprint = 'POLYGON((%s %s, %s %s, %s %s, %s %s, %s %s))' % (lng1, lat1, lng2, lat2, lng3, lat3, lng4, lat4, lng1, lat1)\n",
    "    # función de llamada para buscar mosaicos de Sentinel-1 disponibles\n",
    "    queri(footprint)\n",
    "    \n",
    "# descargar el mosaico elegido de Sentinel-1 en la subcarpeta 'entrada'\n",
    "def on_downloadButton_clicked(b, tile_id):\n",
    "    # obtener información del producto\n",
    "    product_info = api.get_product_odata(tile_id)\n",
    "    # comprobar si el producto está disponible\n",
    "    if product_info['Online']:\n",
    "        # compruebe si existe la carpeta de entrada, si no, cree la carpeta de entrada\n",
    "        input_path = os.path.join(directory, 'input')\n",
    "        if not os.path.isdir(input_path):\n",
    "            os.mkdir(input_path)\n",
    "        # cambiar a la subcarpeta de 'entrada' para almacenar el producto\n",
    "        os.chdir(input_path)\n",
    "        # actualizar estado\n",
    "        print('\\nProduct %s is online. Starting download.' % tile_id, flush=True)\n",
    "        # descargar producto\n",
    "        api.download(tile_id)\n",
    "        # volver al directorio de trabajo anterior\n",
    "        os.chdir(directory)\n",
    "    # mensaje de error cuando el producto no está disponible\n",
    "    else:\n",
    "        print('\\nProduct %s is not online. Must be requested manually.\\n' % tile_id, flush=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################\n",
    "##################### CÓDIGO ######################\n",
    "####################################################\n",
    "\n",
    "# comprobar la entrada del usuario si se solicita la descarga de la imagen\n",
    "if download['imageDownload']:\n",
    "    # conectar a la API\n",
    "    api = SentinelAPI(download['username'], download['password'], 'https://scihub.copernicus.eu/dhus')\n",
    "    # crear un mapa con funcionalidad de búsqueda\n",
    "    download_map = ipyleaflet.Map(zoom = 1.4)\n",
    "    download_map.add_control(ipyleaflet.SearchControl(\n",
    "        position = 'topleft',\n",
    "        url = 'https://nominatim.openstreetmap.org/search?format=json&q={s}',\n",
    "        zoom = 5))\n",
    "    download_map.add_control(ipyleaflet.ScaleControl(position='bottomleft'))\n",
    "    display(download_map)\n",
    "    \n",
    "    # crear un widget HTML para mostrar el índice del producto y la fecha de ingestión del mosaico Sentinel-1 seleccionado\n",
    "    html = ipywidgets.HTML('')\n",
    "    control = ipyleaflet.WidgetControl(widget=html, position='topright')\n",
    "    download_map.add_control(control)\n",
    "    \n",
    "    # verifique si se proporciona el archivo AOI y conviértalo a JSON para mostrar la AOI en el mapa\n",
    "    try:\n",
    "        # llama a la función readJSONfromAOI para obtener GeoJSON de un archivo JSON, SHP o KMZ\n",
    "        data_json = readJSONFromAOI('%s/AOI' % directory)\n",
    "        # mostrar la AOI en el mapa de acuerdo con los datos JSON\n",
    "        aoi = ipyleaflet.GeoJSON(data = data_json, style = {'color' : 'green'})\n",
    "        download_map.zoom = 6.5\n",
    "        try:\n",
    "            # Formato GeoJSON si se proporciona KMZ\n",
    "            download_map.center = (aoi.data['features'][0]['geometry']['coordinates'][0][0][0][1],\n",
    "                                   aoi.data['features'][0]['geometry']['coordinates'][0][0][0][0])\n",
    "        except:\n",
    "            # Formato GeoJSON si se proporciona JSON o SHP\n",
    "            download_map.center = (aoi.data['features'][0]['geometry']['coordinates'][0][0][1],\n",
    "                                   aoi.data['features'][0]['geometry']['coordinates'][0][0][0])\n",
    "        download_map.add_layer(aoi)\n",
    "        # buscar mosaicos de Sentinel-1 disponibles según los datos JSON\n",
    "        footprint = geojson_to_wkt(data_json)\n",
    "        queri(footprint)\n",
    "\n",
    "    # si no se proporciona un AOI, debe seleccionarse manualmente\n",
    "    except FileNotFoundError:\n",
    "        # crear una función de control de dibujo\n",
    "        draw_control = ipyleaflet.DrawControl(circlemarker={},\n",
    "                                              polyline={},\n",
    "                                              polygon={'shapeOptions':{'color':'green'}},\n",
    "                                              rectangle={'shapeOptions':{'color':'green'}})\n",
    "        # agrega la función de control de dibujo al mapa\n",
    "        download_map.add_control(draw_control)\n",
    "        # Crear un botón de búsqueda y función de llamada para buscar mosaicos de Sentinel-1 disponibles cuando se hace clic\n",
    "        searchButton = ipywidgets.Button(description = 'Search')\n",
    "        searchButton.on_click(on_searchButton_clicked)\n",
    "        display(searchButton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesamiento\n",
    "\n",
    "<img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/charts/chart3.png?raw=1\" width=\"1000\"/>\n",
    "\n",
    "Si existe más de una imagen de Sentinel-1 en la subcarpeta *'entrada'*, el usuario puede seleccionar cuál se utilizará para el procesamiento. El subconjunto se genera de acuerdo con el archivo AOI en la subcarpeta *'AOI'*. Si no se proporciona un archivo AOI, un mapa interactivo permite dibujar y descargar el área de interés haciendo clic en el botón *'Exportar'* - dentro del mapa o cargar directamente un archivo AOI almacenado localmente. Posteriormente, se realizan los siguientes pasos de procesamiento:\n",
    "\n",
    "1. ***Aplicar el archivo de órbita***: El archivo de órbita proporciona información precisa sobre la posición y la velocidad del satélite. Con base en esta información, se actualizan los vectores de estado de la órbita en los metadatos del producto. Los archivos de órbita precisos están disponibles de días a semanas después de la generación del producto. Dado que este es un paso de procesamiento opcional, la herramienta continuará el flujo de trabajo en caso de que el archivo de órbita aún no esté disponible para permitir aplicaciones de mapeo rápido.\n",
    "\n",
    "\n",
    "2. ***Eliminación de ruido térmico***: la corrección de ruido térmico se aplica a los productos Sentinel-1 Nivel-1 GRD que aún no se han corregido.\n",
    "\n",
    "\n",
    "3. ***Calibración radiométrica***: El objetivo de esta calibración de SAR es proporcionar imágenes en las que los valores de los píxeles se puedan relacionar directamente con la retrodispersión de la escena de radar. Aunque las imágenes de SAR no calibradas son suficientes para un uso cualitativo, las imágenes de SAR calibradas son esenciales para el uso cuantitativo de los datos de SAR.\n",
    "\n",
    "\n",
    "4. ***Filtrado de puntos***: las imágenes SAR tienen texturas inherentes llamadas puntos que degradan la calidad de la imagen y dificultan la interpretación de las características. Estos puntos son causados por la interferencia aleatoria constructiva y destructiva de las ondas de retorno desfasadas pero coherentes y retro-dispersadas por la dispersión elemental dentro de cada celda de resolución. La reducción de ruido de estos puntos se puede aplicar mediante filtrado espacial o procesamiento multilook. En este paso se utiliza un filtro de tipo Lee con un tamaño de ventana de 5 x 5.\n",
    "\n",
    "\n",
    "5. ***Corrección del terreno***: Debido a las variaciones topográficas de una escena y la inclinación del sensor de satélite, las distancias en las imágenes SAR pueden distorsionarse. Los datos que no se dirijan directamente a la ubicación del nadir del sensor tendrán cierta distorsión. Por lo tanto, las correcciones del terreno están destinadas a compensar estas deformaciones para permitir una representación geométrica realista en la imagen.\n",
    "\n",
    "\n",
    "6. ***Binarización***: para obtener una máscara de inundación binaria, se analiza el histograma para separar el agua de los píxeles que no son de agua. Debido a la geometría lateral de los sensores SAR y la superficie del agua comparativamente lisa, solo una proporción muy pequeña de retrodispersión se refleja en el sensor, lo que genera valores de píxeles comparativamente bajos en el histograma. El umbral utilizado para la separación se calcula automáticamente utilizando las implementaciones de <a href=\"https://scikit-image.org/\"> scikit-image </a> y un uso combinado del <a href = \"https: // doi .org / 10.1111 / j.1749-6632.1965.tb11715.x \"> método mínimo </a> y el <a href =\" https://www.semanticscholar.org/paper/A-threshold-selection-method-from- gray-level-Otsu / 1d4816c612e38dac86f2149af667a5581686cdef? p2df \"> método de Otsu </a>. La capa <a href=\"http://due.esrin.esa.int/page_globcover.php\"> GlobCover </a> de la Agencia Espacial Europea se utiliza para enmascarar los cuerpos de agua permanentes.\n",
    "\n",
    "\n",
    "7. ***Filtrado de manchas***: En este paso se utiliza un filtro de mediana con un tamaño de ventana de 7 x 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     7,
     61,
     98,
     118,
     129
    ]
   },
   "outputs": [],
   "source": [
    "# Click para iniciar\n",
    "\n",
    "####################################################\n",
    "############ DEFINICIONES DE FUNCIONES #############\n",
    "####################################################\n",
    "\n",
    "# crear producto S1\n",
    "def getScene(path):\n",
    "    # establecer la ruta correcta del archivo de entrada y crear el producto S1\n",
    "    if len(files) is 1:\n",
    "        file_path = path\n",
    "    else:\n",
    "        file_path = path.selected\n",
    "    S1_source = snappy.ProductIO.readProduct(file_path)\n",
    "\n",
    "    # leer las coordenadas geográficas de los metadatos de imágenes de Sentinel-1\n",
    "    meta_data = S1_source.getMetadataRoot().getElement('Abstracted_Metadata')\n",
    "    # ubicar el centro del mapa de acuerdo con la imagen Sentinel-1\n",
    "    center = (meta_data.getAttributeDouble('centre_lat'), meta_data.getAttributeDouble('centre_lon'))\n",
    "    locations = [[{'lat' : meta_data.getAttributeDouble('first_near_lat'), 'lng' : meta_data.getAttributeDouble('first_near_long')},\n",
    "                  {'lat' : meta_data.getAttributeDouble('last_near_lat'),  'lng' : meta_data.getAttributeDouble('last_near_long')},\n",
    "                  {'lat' : meta_data.getAttributeDouble('last_far_lat'),   'lng' : meta_data.getAttributeDouble('last_far_long')},\n",
    "                  {'lat' : meta_data.getAttributeDouble('first_far_lat'),  'lng' : meta_data.getAttributeDouble('first_far_long')}]]\n",
    "\n",
    "    # crea un mapa interactivo\n",
    "    basic_map = ipyleaflet.Map(center = center, zoom = 7.5)\n",
    "    # define un polígono fijo que ilustra la imagen de Sentinel-1\n",
    "    polygon_fix = ipyleaflet.Polygon(locations = locations, color='royalblue')\n",
    "    basic_map.add_layer(polygon_fix)\n",
    "    # muestra el mapa\n",
    "    basic_map.add_control(ipyleaflet.ScaleControl(position='bottomleft'))\n",
    "    display(basic_map)\n",
    "    \n",
    "    # verifique si se proporciona el archivo del AOI y conviértalo a JSON para mostrar el AOI en el mapa\n",
    "    try:\n",
    "        # llama a la función readJSONfromAOI para obtener GeoJSON de un archivo JSON, SHP o KMZ\n",
    "        data_json = readJSONFromAOI('%s/AOI' % directory)\n",
    "        # mostrar el AOI en el mapa de acuerdo con los datos JSON\n",
    "        basic_map.add_layer(ipyleaflet.GeoJSON(data = data_json, style = {'color' : 'green'}))\n",
    "        # aplicar el subconjunto de acuerdo con los datos JSON\n",
    "        footprint = geojson_to_wkt(data_json)\n",
    "        # ejecutar el procesamiento\n",
    "        processing(S1_source, footprint)\n",
    "        \n",
    "    # si no se proporciona un AOI, debe seleccionarse manualmente\n",
    "    except:\n",
    "        # polígono editable que determina el AOI\n",
    "        polygon_flex = ipyleaflet.Polygon(locations = locations,\n",
    "                                          color = 'green',\n",
    "                                          fill_color = 'green',\n",
    "                                          transform = True)\n",
    "        basic_map.add_layer(polygon_flex)\n",
    "        # Crear un botón de proceso y la función de llamada para comenzar a procesar cuando se hace clic\n",
    "        processButton = ipywidgets.Button(description = 'Start Processing')\n",
    "        processButton.on_click(functools.partial(on_processButton_clicked,\n",
    "                                                 S1_source = S1_source,\n",
    "                                                 polygon_flex = polygon_flex))\n",
    "        display(processButton)\n",
    "    \n",
    "# calcular y devolver el umbral de entrada de la 'Banda'\n",
    "# SNAP API: https://step.esa.int/docs/v6.0/apidoc/engine/\n",
    "def getThreshold(S1_band):\n",
    "    # leer la banda\n",
    "    w = S1_band.getRasterWidth()\n",
    "    h = S1_band.getRasterHeight()\n",
    "    band_data = np.zeros(w * h, np.float32)\n",
    "    S1_band.readPixels(0, 0, w, h, band_data)\n",
    "    band_data.shape = h * w\n",
    "\n",
    "    # calcular el umbral usando el método Otsu \n",
    "    threshold_otsu = skimage.filters.threshold_otsu(band_data)\n",
    "    # calcular el umbral utilizando el método mínimo\n",
    "    threshold_minimum = skimage.filters.threshold_minimum(band_data)\n",
    "    # obtener el número de píxeles para ambos umbrales\n",
    "    numPixOtsu = len(band_data[abs(band_data - threshold_otsu) < 0.1])\n",
    "    numPixMinimum = len(band_data[abs(band_data - threshold_minimum) < 0.1])\n",
    "\n",
    "    # si el número de píxeles en el umbral mínimo es inferior al 1% del número de píxeles en el umbral Otsu\n",
    "    if abs(numPixMinimum/numPixOtsu) < 0.001:\n",
    "        # ajustar los datos de la banda de acuerdo\n",
    "        if threshold_otsu < threshold_minimum:\n",
    "            band_data = band_data[band_data < threshold_minimum]\n",
    "            threshold_minimum = skimage.filters.threshold_minimum(band_data)\n",
    "        else:\n",
    "            band_data = band_data[band_data > threshold_minimum]\n",
    "            threshold_minimum = skimage.filters.threshold_minimum(band_data)\n",
    "    \n",
    "        numPixMinimum = len(band_data[abs(band_data - threshold_minimum) < 0.1])\n",
    "\n",
    "    # seleccionar el umbral final\n",
    "    if abs(numPixMinimum/numPixOtsu) < 0.001:\n",
    "        threshold = threshold_otsu\n",
    "    else:\n",
    "        threshold = threshold_minimum\n",
    "\n",
    "    return threshold\n",
    "\n",
    "# calcular la máscara binaria de la entrada de tipo 'Producto' con respecto a la expresión en la matriz de cadenas\n",
    "def binarization(S1_product, expressions):\n",
    "\n",
    "    BandDescriptor = jpy.get_type('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor')\n",
    "    targetBands = jpy.array('org.esa.snap.core.gpf.common.BandMathsOp$BandDescriptor', len(expressions))\n",
    "\n",
    "    # bucle a través de bandas\n",
    "    for i in range(len(expressions)):\n",
    "        targetBand = BandDescriptor()\n",
    "        targetBand.name = '%s' % S1_product.getBandNames()[i]\n",
    "        targetBand.type = 'float32'\n",
    "        targetBand.expression = expressions[i]\n",
    "        targetBands[i] = targetBand\n",
    "    \n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('targetBands', targetBands)    \n",
    "    mask = snappy.GPF.createProduct('BandMaths', parameters, S1_product)\n",
    "\n",
    "    return mask\n",
    "\n",
    "# botón de inicio de procesamiento \n",
    "def on_processButton_clicked(b, S1_source, polygon_flex):\n",
    "    # get coordinates and store in WKT format variable\n",
    "    lng1, lat1 = polygon_flex.locations[0][0]['lng'], polygon_flex.locations[0][0]['lat']\n",
    "    lng2, lat2 = polygon_flex.locations[0][1]['lng'], polygon_flex.locations[0][1]['lat']\n",
    "    lng3, lat3 = polygon_flex.locations[0][2]['lng'], polygon_flex.locations[0][2]['lat']\n",
    "    lng4, lat4 = polygon_flex.locations[0][3]['lng'], polygon_flex.locations[0][3]['lat']\n",
    "    footprint = 'POLYGON((%s %s, %s %s, %s %s, %s %s, %s %s))' % (lng1, lat1, lng2, lat2, lng3, lat3, lng4, lat4, lng1, lat1)\n",
    "    # ejecutar el procesamiento\n",
    "    processing(S1_source, footprint)\n",
    "\n",
    "# pasos del procesamiento\n",
    "def processing(S1_source, footprint):\n",
    "    \n",
    "    # Operador de recorte o subconjunto\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('copyMetadata', True)\n",
    "    geom = snappy.WKTReader().read(footprint)\n",
    "    parameters.put('geoRegion', geom)\n",
    "    parameters.put('sourceBands', sourceBands)\n",
    "    S1_crop = snappy.GPF.createProduct('Subset', parameters, S1_source)\n",
    "    # actualizar estado\n",
    "    print('\\nSubset successfully generated.\\n', flush=True)\n",
    "    \n",
    "    # aplicar el Apply-Orbit-File\n",
    "    print('1. Apply Orbit File:          ', end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    parameters = snappy.HashMap()\n",
    "    # Continuar con el cálculo en caso de que aún no haya ningún archivo de órbita disponible.\n",
    "    parameters.put('continueOnFail', True)\n",
    "    S1_Orb = snappy.GPF.createProduct('Apply-Orbit-File', parameters, S1_crop)\n",
    "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # Operador de eliminación de ruido térmico\n",
    "    print('2. Thermal Noise Removal:     ', end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('removeThermalNoise', True)\n",
    "    S1_Thm = snappy.GPF.createProduct('ThermalNoiseRemoval', parameters, S1_Orb)\n",
    "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # operador de calibración\n",
    "    print('3. Radiometric Calibration:   ', end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('outputSigmaBand', True)\n",
    "    S1_Cal = snappy.GPF.createProduct('Calibration', parameters, S1_Thm)\n",
    "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # operador de filtrado de ruido o Speckle\n",
    "    print('4. Speckle Filtering:         ', end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('filter', 'Lee')\n",
    "    parameters.put('filterSizeX', 5)\n",
    "    parameters.put('filterSizeY', 5)\n",
    "    S1_Spk = snappy.GPF.createProduct('Speckle-Filter', parameters, S1_Cal)\n",
    "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # Conversión lineal a db\n",
    "    S1_Spk_db = snappy.GPF.createProduct('LinearToFromdB', snappy.HashMap(), S1_Spk)\n",
    "\n",
    "    # Operador de corrección de terreno\n",
    "    print('5. Terrain Correction:        ', end='', flush=True)\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('demName', 'SRTM 1Sec HGT')\n",
    "    parameters.put('demResamplingMethod', 'BILINEAR_INTERPOLATION')\n",
    "    parameters.put('imgResamplingMethod', 'BILINEAR_INTERPOLATION')\n",
    "    parameters.put('pixelSpacingInMeter', 10.0)\n",
    "    parameters.put('nodataValueAtSea', False)\n",
    "    parameters.put('saveSelectedSourceBand', True)\n",
    "    S1_TC = snappy.GPF.createProduct('Terrain-Correction', parameters, S1_Spk_db)\n",
    "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # Binarización\n",
    "    print('6. Binarization:              ', end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    # añadir la banda GlobCover\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('landCoverNames', 'GlobCover')\n",
    "    GlobCover = snappy.GPF.createProduct('AddLandCover', parameters, S1_TC)\n",
    "    # matriz de cadena vacía para expresiones matemáticas de la banda de binarización\n",
    "    expressions = ['' for i in range(S1_TC.getNumBands())]\n",
    "    # matriz vacía para el umbral (s)\n",
    "    thresholds = np.zeros(S1_TC.getNumBands())\n",
    "    # bucle a través de bandas\n",
    "    for i in range(S1_TC.getNumBands()):\n",
    "        # calcular el umbral de la banda y almacenarlo en una matriz flotante\n",
    "        # utilice el producto S1_Spk_db por motivos de rendimiento. S1_TC provoca valores 0\n",
    "        # que distorsionan el histograma y, por lo tanto, el resultado del umbral\n",
    "        thresholds[i] = getThreshold(S1_Spk_db.getBandAt(i))\n",
    "        # formular la expresión según el umbral y almacenarla en una matriz de cadenas\n",
    "        expressions[i] = 'if (%s < %s && land_cover_GlobCover != 210) then 1 else NaN' % (S1_TC.getBandNames()[i], thresholds[i])\n",
    "    # hacer binarización\n",
    "    S1_floodMask = binarization(GlobCover, expressions)\n",
    "    print('--- %.2f seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # Operador de filtro de manchas\n",
    "    print('7. Speckle Filtering:         ', end='', flush=True)\n",
    "    start_time = time.time()\n",
    "    parameters = snappy.HashMap()\n",
    "    parameters.put('filter', 'Median')\n",
    "    parameters.put('filterSizeX', 5)\n",
    "    parameters.put('filterSizeY', 5)\n",
    "    # definir la máscara de inundación como global para un acceso posterior\n",
    "    global S1_floodMask_Spk\n",
    "    S1_floodMask_Spk = snappy.GPF.createProduct('Speckle-Filter', parameters, S1_floodMask)\n",
    "    print('--- %.2f  seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "    # salida\n",
    "    if plotResoluts:\n",
    "        print('8. Plot:                      ', end='', flush=True)\n",
    "        start_time = time.time()\n",
    "        for i in range(S1_TC.getNumBands()):\n",
    "            plotBand(S1_TC.getBandAt(i), thresholds[i])\n",
    "        print('--- %.2f seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################\n",
    "###################### CÓDIGO ######################\n",
    "####################################################\n",
    "\n",
    "# filtrar la(s) polarización(es) requerida(s) y establecer el nombre del archivo de salida \n",
    "if polarisations == 'ambas':\n",
    "    sourceBands = 'Amplitude_VH,Intensity_VH,Amplitude_VV,Intensity_VV'\n",
    "    output_extensions   = 'processed_VHVV'\n",
    "elif polarisations == 'VH':\n",
    "    sourceBands = 'Amplitude_VH,Intensity_VH'\n",
    "    output_extensions   = 'processed_VH'\n",
    "elif polarisations == 'VV':\n",
    "    sourceBands = 'Amplitude_VV,Intensity_VV'\n",
    "    output_extensions   = 'processed_VV'\n",
    "\n",
    "# ruta del archivo de entrada .zip de Sentinel-1\n",
    "input_path = os.path.join(directory, 'input')\n",
    "# matriz de cadena vacía para almacenar archivos Sentinel-1 en la subcarpeta 'entrada'\n",
    "files = []\n",
    "# agregar archivos a la lista\n",
    "for file in glob.glob1(input_path, '*.zip'):\n",
    "    files.append(file)\n",
    "# seleccione el archivo de entrada y comience a procesar si solo hay un archivo Sentinel-1 disponible\n",
    "if len(files) == 1:\n",
    "    input_name = files[0]\n",
    "    print('Selected:  %s\\n' % input_name, flush=True)\n",
    "    # aplicar subconjunto de acuerdo con los datos JSON\n",
    "    getScene('%s/%s' % (input_path, input_name))\n",
    "# abrir diálogo para seleccionar el archivo de entrada si hay más de uno disponible\n",
    "else:\n",
    "    print('More or less than one Sentinel-1 files have been found. Please select.', flush=True)\n",
    "    fc = FileChooser(input_path)\n",
    "    fc.register_callback(getScene)\n",
    "    display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exportar Datos\n",
    "\n",
    "<img src=\"https://github.com/UN-SPIDER/radar-based-flood-mapping-spanish/blob/main/resources/charts/chart4.png?raw=1\" width=\"1000\"/>\n",
    "\n",
    "La máscara de inundación procesada se exporta como un GeoTIFF, SHP, KML y GeoJSON y se almacena en la subcarpeta *'salida'*. Un mapa interactivo muestra la máscara de inundación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Click para iniciar\n",
    "\n",
    "####################################################\n",
    "###################### CÓDIGO ######################\n",
    "####################################################\n",
    "\n",
    "print('Exporting...\\n', flush=True)\n",
    "# compruebe si existen carpetas de salida, si no crea las carpetas\n",
    "output_path = os.path.join(directory, 'output')\n",
    "if not os.path.isdir(output_path):\n",
    "    os.mkdir(output_path)\n",
    "GeoTIFF_path = os.path.join(output_path, 'GeoTIFF')\n",
    "if not os.path.isdir(GeoTIFF_path):\n",
    "    os.mkdir(GeoTIFF_path)\n",
    "SHP_path = os.path.join(output_path, 'SHP')\n",
    "if not os.path.isdir(SHP_path):\n",
    "    os.mkdir(SHP_path)\n",
    "KML_path = os.path.join(output_path, 'KML')\n",
    "if not os.path.isdir(KML_path):\n",
    "    os.mkdir(KML_path)\n",
    "GeoJSON_path = os.path.join(output_path, 'GeoJSON')\n",
    "if not os.path.isdir(GeoJSON_path):\n",
    "    os.mkdir(GeoJSON_path)\n",
    "# obtener el nombre del archivo si se utilizó el selector de archivos\n",
    "if len(files) is not 1: input_name = fc.selected_filename\n",
    "\n",
    "# escribir el archivo de salida como GeoTIFF\n",
    "print('1. GeoTIFF:                   ', end='', flush=True)\n",
    "start_time = time.time()\n",
    "snappy.ProductIO.writeProduct(S1_floodMask_Spk, '%s/%s_%s' % (GeoTIFF_path, os.path.splitext(input_name)[0], output_extensions), 'GeoTIFF')\n",
    "print('--- %.2f seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "# convertir el GeoTIFF a SHP\n",
    "print('2. SHP:                       ', end='', flush=True)\n",
    "start_time = time.time()\n",
    "# permitir que GDAL lance excepciones de Python\n",
    "gdal.UseExceptions()\n",
    "open_image = gdal.Open('%s/%s_%s.tif' % (GeoTIFF_path, os.path.splitext(input_name)[0], output_extensions))\n",
    "srs = osr.SpatialReference()\n",
    "srs.ImportFromWkt(open_image.GetProjectionRef())\n",
    "shp_driver = ogr.GetDriverByName('ESRI Shapefile')\n",
    "# matriz de cadena vacía para bandas en GeoTIFF\n",
    "output_shp = ['' for i in range(open_image.RasterCount)]\n",
    "if open_image.RasterCount == 1:\n",
    "    output_shp[0] = '%s/%s_processed_%s' % (SHP_path, os.path.splitext(input_name)[0], polarisations)\n",
    "else:\n",
    "    VH_SHP_path = os.path.join(SHP_path, 'VH')\n",
    "    if not os.path.isdir(VH_SHP_path):\n",
    "        os.mkdir(VH_SHP_path)\n",
    "    VV_SHP_path = os.path.join(SHP_path, 'VV')\n",
    "    if not os.path.isdir(VV_SHP_path):\n",
    "        os.mkdir(VV_SHP_path)\n",
    "    output_shp[0] = '%s/%s_processed_VH' % (VH_SHP_path, os.path.splitext(input_name)[0])\n",
    "    output_shp[1] = '%s/%s_processed_VV' % (VV_SHP_path, os.path.splitext(input_name)[0])\n",
    "# bucles a través de bandas en GeoTIFF\n",
    "for i in range(open_image.RasterCount):\n",
    "    input_band = open_image.GetRasterBand(i+1)\n",
    "    output_shapefile = shp_driver.CreateDataSource(output_shp[i] + '.shp')\n",
    "    new_shapefile = output_shapefile.CreateLayer(output_shp[i], srs=srs)\n",
    "    new_shapefile.CreateField(ogr.FieldDefn('DN', ogr.OFTInteger))\n",
    "    gdal.Polygonize(input_band, input_band.GetMaskBand(), new_shapefile, 0, [], callback=None)\n",
    "    # filtra atributos con valores distintos de 1 (debe ser NaN o el valor respectivo)\n",
    "    new_shapefile.SetAttributeFilter('DN != 1')\n",
    "    for feat in new_shapefile:\n",
    "        new_shapefile.DeleteFeature(feat.GetFID())\n",
    "    new_shapefile.SyncToDisk()\n",
    "print('--- %.2f seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "# convertir de SHP a KML\n",
    "print('3. KML:                       ', end='', flush=True)\n",
    "start_time = time.time()\n",
    "if open_image.RasterCount == 1:\n",
    "    shp_file = gdal.OpenEx('%s/%s_processed_%s.shp' % (SHP_path, os.path.splitext(input_name)[0], polarisations))\n",
    "    ds = gdal.VectorTranslate('%s/%s_processed_%s.kml' % (KML_path, os.path.splitext(input_name)[0], polarisations), shp_file, format='KML')\n",
    "    del ds\n",
    "else:\n",
    "    shp_file_VH = gdal.OpenEx('%s/%s_processed_VH.shp' % (VH_SHP_path, os.path.splitext(input_name)[0]))\n",
    "    ds_VH = gdal.VectorTranslate('%s/%s_processed_VH.kml' % (KML_path, os.path.splitext(input_name)[0]), shp_file_VH, format='KML')\n",
    "    del ds_VH\n",
    "    shp_file_VV = gdal.OpenEx('%s/%s_processed_VV.shp' % (VV_SHP_path, os.path.splitext(input_name)[0]))\n",
    "    ds_VV = gdal.VectorTranslate('%s/%s_processed_VV.kml' % (KML_path, os.path.splitext(input_name)[0]), shp_file_VV, format='KML')\n",
    "    del ds_VV\n",
    "print('--- %.2f seconds ---' % (time.time() - start_time), flush=True)\n",
    "\n",
    "# convertir de SHP a GeoJSON\n",
    "print('4. GeoJSON:                   ', end='', flush=True)\n",
    "start_time = time.time()\n",
    "if open_image.RasterCount == 1:\n",
    "    shp_file = geopandas.read_file('%s/%s_processed_%s.shp' % (SHP_path, os.path.splitext(input_name)[0], polarisations))\n",
    "    shp_file.to_file('%s/%s_processed_%s.json' % (GeoJSON_path, os.path.splitext(input_name)[0], polarisations), driver='GeoJSON')\n",
    "else:\n",
    "    shp_file_VH = geopandas.read_file('%s/%s_processed_VH.shp' % (VH_SHP_path, os.path.splitext(input_name)[0]))\n",
    "    shp_file_VH.to_file('%s/%s_processed_VH.json' % (GeoJSON_path, os.path.splitext(input_name)[0]), driver='GeoJSON')    \n",
    "    shp_file_VV = geopandas.read_file('%s/%s_processed_VV.shp' % (VV_SHP_path, os.path.splitext(input_name)[0]))\n",
    "    shp_file_VV.to_file('%s/%s_processed_VV.json' % (GeoJSON_path, os.path.splitext(input_name)[0]), driver='GeoJSON')\n",
    "print('--- %.2f seconds ---\\n' % (time.time() - start_time), flush=True)\n",
    "print('Files successfuly stored under %s.\\n' % output_path, flush=True)\n",
    "\n",
    "# gráficar resultados\n",
    "results_map = ipyleaflet.Map(zoom=9, basemap=ipyleaflet.basemaps.OpenStreetMap.Mapnik)    \n",
    "if open_image.RasterCount == 1:\n",
    "    file = '%s/%s_processed_%s.json' % (GeoJSON_path, os.path.splitext(input_name)[0], polarisations)\n",
    "    with open(file, 'r') as f:\n",
    "        data_json = json.load(f) \n",
    "    mask = ipyleaflet.GeoJSON(data = data_json, name = 'Flood Mask', style = {'color':'blue', 'opacity':'1', 'fillColor':'blue', 'fillOpacity':'1', 'weight':'0.8'})\n",
    "    results_map.add_layer(mask)\n",
    "    results_map.center = (mask.data['features'][0]['geometry']['coordinates'][0][0][1],\n",
    "                          mask.data['features'][0]['geometry']['coordinates'][0][0][0])\n",
    "else:\n",
    "    file_VV = '%s/%s_processed_VV.json' % (GeoJSON_path, os.path.splitext(input_name)[0])\n",
    "    with open(file_VV, 'r') as f_VV:\n",
    "        data_json_VV = json.load(f_VV)\n",
    "    mask_VV = ipyleaflet.GeoJSON(data = data_json_VV, name = 'Flood Mask: VV', style = {'color':'red', 'opacity':'1', 'fillColor':'red', 'fillOpacity':'1', 'weight':'0.8'})\n",
    "    results_map.add_layer(mask_VV)\n",
    "    results_map.center = (mask_VV.data['features'][0]['geometry']['coordinates'][0][0][1],\n",
    "                          mask_VV.data['features'][0]['geometry']['coordinates'][0][0][0])  \n",
    "    file_VH = '%s/%s_processed_VH.json' % (GeoJSON_path, os.path.splitext(input_name)[0])\n",
    "    with open(file_VH, 'r') as f_VH:\n",
    "        data_json_VH = json.load(f_VH)\n",
    "    mask_VH = ipyleaflet.GeoJSON(data = data_json_VH, name = 'Flood Mask: VH', style = {'color':'blue', 'opacity':'1', 'fillColor':'blue', 'fillOpacity':'1', 'weight':'0.8'})\n",
    "    results_map.add_layer(mask_VH)\n",
    "results_map.add_control(ipyleaflet.FullScreenControl())\n",
    "results_map.add_control(ipyleaflet.LayersControl(position='topright'))\n",
    "results_map.add_control(ipyleaflet.ScaleControl(position='bottomleft'))\n",
    "display(results_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
